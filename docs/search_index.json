[["index.html", "Spatio-temporal yield variation to precipitation within a field 1 Introduction", " Spatio-temporal yield variation to precipitation within a field Emmanuela van Versendaal 2024-08-07 1 Introduction This bookdown provides R code to evaluate whether the same spatio-temporal patterns can be identified using both observed yield monitor data from combines and predicted yield data derived from Sentinel-2 imagery. Understanding spatio-temporal yield variation within a field is crucial for accurately identifying yield fluctuations and improving site-specific management practices. Precipitation is a key factor influencing yield variation across years, and it also impacts crop response to the application of inputs. Despite this, there is a lack of studies assessing whether yield response to precipitation varies within a field. Typically, analyzing these patterns requires yield monitor data collected over multiple years. However, not all farmers have access to such data. Therefore, it is important to determine if the same spatio-temporal patterns can be captured using both observed yield monitor data and predicted data derived from remote sensing, particularly Sentinel-2 satellite imagery, chosen for its high spatial and temporal resolution. "],["data-collection-wrangling-exploration.html", "2 Data collection, wrangling &amp; exploration 2.1 Retrieve satellite data 2.2 Clean yield monitor data 2.3 CP period 2.4 Data exploration 2.5 Split field in training-testing 2.6 Reference", " 2 Data collection, wrangling &amp; exploration Three types of data were collected and processed: (2.1) satellite imagery from Sentinel-2, (2.2) yield monitor data from combines, and (2.3) daily precipitation data from CHIRPS. Data were collected from sixteen fields. Twelve of these fields were used to train the model for predicting yield using satellite data, while the remaining four fields were used to test the model (step 2.5). 2.1 Retrieve satellite data 2.1.1 Import libraries Run the following code only if you never installer rgee package in R. ### To install Rgee #remove.packages(“reticulate”) #install.packages(“reticulate”, dependencies = TRUE) #remotes::install_github(“r-spatial/rgee”) ##No Run ## If it is the first time to use RGEE is necessary install gcloud cli #reticulate::py_install(“earthengine-api”, envname = “r-miniconda”) #reticulate::py_install(“numpy”, envname = “/Users/emmavanversendaal/Library/r-miniconda-arm64/envs/r-reticulate”) #reticulate::py_install(“google-cloud-storage”) #reticulate::py_config() Import libraries and clean environment # # Packages to be used # library_names &lt;- c(“sp”, # (Bivand et al., 2012) # “sf”, # (Pebesma, 2018) # “raster”, # (Hijmans, 2023) # “tidyverse”, # (Wickham et al., 2019) # “rgee”, # (Aybar, 2024) # “tidyrgee”) # (Arno and Erickson, 2022) # # Iterate over each library name # for (lib_name in library_names) { # # Check if the library is already installed # if (!require(lib_name, character.only = TRUE)) { # # If the library is not installed, install it # install.packages(lib_name, dependencies = TRUE) # # Load the library # library(lib_name, character.only = TRUE) # } else { # # If the library is already installed, load it # library(lib_name, character.only = TRUE) # } # } Rgee configuration. Run this code to initialize session in Google Earth Engine. # rgee::ee_check() # ee_clean_user_credentials() # ee_Authenticate(user=‘ee-evanversendaal’) # ee_Initialize(user=‘ee-evanversendaal’) Run the following Functions: 1) Clouds mask function to identify pixels that are likely to be a cloud; 2) to calculate Green Chlorophyll Vegetation Index (GCVI) # ## 1) Clouds masking function ## # # This function is to filter the clouds, to have images with clear conditions # maskS2clouds &lt;- function(image) { # qa = image$select(‘QA60’); # # Bits 10 and 11 are clouds and cirrus, respectively. # cloudBitMask = bitwShiftL(1,10) # cirrusBitMask = bitwShiftL(1, 11) # # Both flags should be set to zero, indicating clear conditions. # mask_data = qa$bitwiseAnd(cloudBitMask)$ # eq(0)$And(qa$bitwiseAnd(cirrusBitMask)$eq(0)); # return(image$updateMask(mask_data)$divide(10000)) # } # ## 2) Function to obatin GCVI ## # getindex_GCVI &lt;- function(image) { # #Index &lt;- image$normalizedDifference(c(“B8”, “B4&quot;))$rename(‘Index’) # Index &lt;- image$expression( # expression = “(NIR/GREEN)-1”, # opt_map = list( # “NIR” = image$select(“B8”), # “GREEN” = image$select(“B3”) # ) # )$rename(“Index”) # return(image$addBands(Index)) # } 2.1.2 Field identification In this step, it’s essential to specify the field identification because the code is designed to automatically run across different fields. By defining the specific field at this stage, you ensure that the correct data is selected for analysis. This setup allows for a streamlined and efficient workflow, enabling the code to process data for multiple fields as needed. #FARM_NAME = &quot;...&quot; 2.1.3 GCVI Peak detection Obtain the path to the field polygon/boundary. This step is crucial because it ensures that only the satellite image specific to the field is used. ## 1. Create the polygons path ## # Path_polygon &lt;- data.frame( # path = list.files(&quot;../1_Data/1_Polygon&quot;, # pattern = &quot;.shp&quot;, full.names = T, recursive = T)) %&gt;% # mutate(path2 = path) %&gt;% # separate(path2, into = c(&quot;..&quot;,&quot;Data_file&quot;,&quot;Polygon&quot;,&quot;Farm&quot;), sep = &quot;/&quot;) %&gt;% # mutate(Farm = str_replace(Farm, &quot;_pol.shp&quot;, &quot;&quot;)) %&gt;% # dplyr::select(path, Farm) %&gt;% # #remove the filter if you want to run all farms # dplyr::filter(Farm == FARM_NAME) Obtain GCVI peak serie For this study, remote sensing data was sourced from the Sentinel-2 satellite dataset. More details can be found here: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED#description Identify the peak moment of the Green Chlorophyll Vegetation Index (GCVI) for the entire field. Then, determine a range of days around this peak, as well as separate ranges of days around the dates that are 30 days before and 30 days after the peak. This approach allows us to select three key images during the crop growing season. The use of these ranges is necessary because it’s not always possible to obtain a clear image (with less than 2% cloud cover) on specific days, so having a broader window increases the chances of finding a suitable image. # for (file in 1:nrow(Path_polygon)){ # ## 1. Defining AOI, boundary, and sample points for all the fields ## # AOI &lt;- sf::st_read(dsn = Path_polygon[file, 1], # stringsAsFactors = F, quiet = F) %&gt;% # sf::st_geometry() %&gt;% # st_cast(&quot;MULTIPOLYGON&quot;) %&gt;% # st_zm(drop = TRUE) %&gt;% # sf_as_ee() # ## 2. Retrieve Spatial layer ## # ### 2.1. Extracting the bands # s2bands &lt;- ee$ImageCollection(&quot;COPERNICUS/S2_HARMONIZED&quot;)$ # filterBounds(AOI)$ # # Period that we want: # filterDate(&quot;2017-01-01&quot;,&quot;2024-01-01&quot;)$ # # Filter the images with more than 5% clouds: # filter(ee$Filter$lt(&quot;CLOUDY_PIXEL_PERCENTAGE&quot;, 3))$ # map(maskS2clouds)$ # map(function(x){ # date &lt;- ee$Date(&quot;x$get(system:time_start&quot;))$format(&quot;YYYY_MM_dd&quot;) # # Bands that we want: # x$select(&quot;B2&quot;,&quot;B3&quot;,&quot;B4&quot;,&quot;B8&quot;) }) # ### 2.2. Extracting the data points to a data frame # s2extraction &lt;- ee_extract( # x = s2bands, # y = AOI, # scale = 10, # fun = ee$Reducer$median(), # sf = FALSE ) %&gt;% # t() %&gt;% # as.data.frame() %&gt;% # rownames_to_column() %&gt;% # separate(rowname, c(&quot;datet1&quot;, &quot;datet2&quot;, &quot;check&quot;, &quot;band&quot;), sep = &quot;_&quot;) # ### 4.3. Index calculation # s2extraction &lt;- s2extraction %&gt;% # pivot_longer(cols = !c(datet1, datet2, check, band), # names_to = &quot;point_id&quot;, # values_to = &quot;values&quot;) %&gt;% # pivot_wider(names_from = band, # values_from = values ) %&gt;% # dplyr::select(&quot;datet1&quot;, &quot;point_id&quot;,&quot;B2&quot;,&quot;B3&quot;,&quot;B4&quot;,&quot;B8&quot;) %&gt;% # mutate(B2 = as.numeric(unlist(B2)), # B3 = as.numeric(unlist(B3)), # B4 = as.numeric(unlist(B4)), # B8 = as.numeric(unlist(B8)), # GCVI = (B8 / B3)-1) # ### 2.4. Data wrangling # s2datapoints &lt;- s2extraction %&gt;% # mutate(date = str_replace(datet1, &quot;X&quot;, &quot;&quot;)) %&gt;% # separate(date, into=c(&quot;asdate&quot;, &quot;remove&quot;), sep=&quot;T1&quot;) %&gt;% # mutate(DATE = ymd(asdate)) %&gt;% # rename(date = DATE) %&gt;% # dplyr::select(point_id, GCVI, NDVI,EVI,date) %&gt;% # mutate(Year=year(date), # Farm = Path_polygon[file, 2]) %&gt;% # dplyr::filter(GCVI&gt;=0) # ### 2.5. Peaks GCVI in each year # sm_maxGCVI &lt;- s2datapoints %&gt;% # na.exclude() %&gt;% # group_by(Year) %&gt;% # ## Fit a polynomial to detect the GCVI peak # mutate(smooth =stats::predict(stats::loess(GCVI~as.numeric(date), # span=.3))) %&gt;% # slice_max(order_by = smooth) %&gt;% # mutate(date_b30 = date - 30, # lb_day_b30 = date_b30 - days(15), # up_day_b30 = date_b30 + days(15), # lb_day = date - days(15), # up_day = date + days(15), # date_30 = date + 30, # lb_day_30 = date_30 - days(15), # up_day_30 = date_30 + days(15)) %&gt;% # distinct(date, .keep_all = TRUE) # write.csv(sm_maxGCVI, # paste0(&quot;../1_Data/2_Spatial_Layer/1_TS_peak/peak_diff_moments/&quot;, # Path_polygon[file,2],&quot;_GCVI.csv&quot;), row.names = F) # ts_gcvi &lt;- s2datapoints %&gt;% # ggplot(aes(x = date, y = GCVI)) + # geom_point() + # geom_smooth(span=.07, color = &quot;#52796F&quot;) + # geom_point(data=sm_maxGCVI, aes(y=smooth),shape = 21, alpha=.7, # color=&quot;grey25&quot;, size=2.5, fill = &quot;#9B2226&quot;) + # scale_x_date(date_breaks = &quot;1 year&quot;, date_labels = &quot;%Y&quot;)+ # theme_bw() # ggsave(paste0(&quot;../3_Output/1_Spat_layer/TimeSerie/&quot;, FARM_NAME, &quot;_GCVI.png&quot;), # height = 4, width = 5) # } 2.1.4 GCVI at pixel level within field Upload peak serie file path Upload the peak serie .csv file created in the steps before. # path_peak &lt;- data.frame( # pathGCVI = list.files(&quot;../1_Data/2_Spatial_Layer/1_TS_peak/peak_diff_moments&quot;, # full.names =T,pattern =&quot;_GCVI.csv&quot;,recursive =T)) %&gt;% # mutate(path = pathGCVI) %&gt;% # separate(path, into = c(&quot;del&quot;, &quot;del1&quot; ,&quot;del2&quot;, &quot;del3&quot;, &quot;del4&quot;,&quot;Farm&quot;), # sep = &quot;/&quot;) %&gt;% # mutate(Farm = str_replace(Farm, &quot;_GCVI.csv&quot;, &quot;&quot;), # Path_polygon = paste0(&quot;../1_Data/1_Polygon/&quot;, Farm, &quot;_pol.shp&quot;)) %&gt;% # dplyr::select(-starts_with(&quot;del&quot;)) %&gt;% # dplyr::filter(Farm == FARM_NAME) Obtain GCVI at pixel level within the field For each year, starting from 2017 (the start of Sentinel-2 data availability), images with less than 2% clouds were obtained for three specific periods: around the GCVI peak, 30 days before the peak, and 30 days after the peak. These images have a pixel resolution of 10 m x 10 m. Additionally, the GCVI was calculated for each of these periods. # ## Peak moment ## # Year &lt;- c(2017,2018,2019,2020,2021,2022,2023) # for (file in 1:nrow(path_peak)){ # AOI &lt;- sf::st_read(dsn = path_peak[file, 3], # polygon # stringsAsFactors = F, # quiet = F) %&gt;% # sf::st_geometry() %&gt;% # st_cast(&quot;MULTIPOLYGON&quot;) %&gt;% # st_zm(drop = TRUE) %&gt;% # sf_as_ee() # for (y in Year){ # peak &lt;- read.csv(path_peak[file, 1]) %&gt;% # dplyr::filter(Year==y) # s2 &lt;- ee$ImageCollection(&quot;COPERNICUS/S2_HARMONIZED&quot;)$ # filterBounds(AOI)$ # filterDate(as.character(peak$lb_day), # as.character(peak$up_day))$ # filter(ee$Filter$lt(&quot;CLOUDY_PIXEL_PERCENTAGE&quot;, 2))$ # map(maskS2clouds)$map(getindex_GCVI)$select(&quot;Index&quot;)$median() # s2_im &lt;- ee$Image(s2)$ # clip(AOI) # s2_raster &lt;- ee_as_rast(s2_im, # region = AOI, # via = &quot;getDownloadURL&quot;, # dsn = paste0(&quot;../1_Data/2_Spatial_Layer/2_VI_raster/Peak/p2/&quot;, # path_peak[file, 2],&quot;_&quot;,y,&quot;_GCVI.tif&quot;), # scale = 10) # } # } # ## Peak - 30 days moment## # Year &lt;- c(2017,2018,2019,2020,2021,2022,2023) # for (file in 1:nrow(path_peak)){ # AOI &lt;- sf::st_read(dsn = path_peak[file, 3], # polygon # stringsAsFactors = F, # quiet = F) %&gt;% # sf::st_geometry() %&gt;% # st_cast(&quot;MULTIPOLYGON&quot;) %&gt;% # st_zm(drop = TRUE) %&gt;% # sf_as_ee() # for (y in Year){ # peak &lt;- read.csv(path_peak[file, 1]) %&gt;% # dplyr::filter(Year==y) # s2 &lt;- ee$ImageCollection(&quot;COPERNICUS/S2_HARMONIZED&quot;)$ # filterBounds(AOI)$ # filterDate(as.character(peak$lb_day_b30), # as.character(peak$up_day_b30))$ # filter(ee$Filter$lt(&quot;CLOUDY_PIXEL_PERCENTAGE&quot;, 2))$ # map(maskS2clouds)$map(getindex_GCVI)$select(&quot;Index&quot;)$median() # s2_im &lt;- ee$Image(s2)$ # clip(AOI) # s2_raster &lt;- ee_as_rast(s2_im, # region = AOI, # via = &quot;getDownloadURL&quot;, # dsn = paste0( # &quot;../1_Data/2_Spatial_Layer/2_VI_raster/Peak_b30/p_b30/&quot;, # path_peak[file, 2],&quot;_&quot;,y,&quot;_GCVI.tif&quot;), # scale = 10) # } # } # ## Peak - 30 days moment## # Year &lt;- c(2017,2018,2019,2020,2021,2022,2023) # for (file in 1:nrow(path_peak)){ # AOI &lt;- sf::st_read(dsn = path_peak[file, 3], # polygon # stringsAsFactors = F, # quiet = F) %&gt;% # sf::st_geometry() %&gt;% # st_cast(&quot;MULTIPOLYGON&quot;) %&gt;% # st_zm(drop = TRUE) %&gt;% # sf_as_ee() # for (y in Year){ # peak &lt;- read.csv(path_peak[file, 1]) %&gt;% # dplyr::filter(Year==y) # s2 &lt;- ee$ImageCollection(&quot;COPERNICUS/S2_HARMONIZED&quot;)$ # filterBounds(AOI)$ # filterDate(as.character(peak$lb_day_30), # as.character(peak$up_day_30))$ # filter(ee$Filter$lt(&quot;CLOUDY_PIXEL_PERCENTAGE&quot;, 2))$ # map(maskS2clouds)$map(getindex_GCVI)$select(&quot;Index&quot;)$median() # s2_im &lt;- ee$Image(s2)$ # clip(AOI) # s2_raster &lt;- ee_as_rast(s2_im, # region = AOI, # via = &quot;getDownloadURL&quot;, # dsn = # paste0(&quot;../1_Data/2_Spatial_Layer/2_VI_raster/Peak_30/p30/&quot;, # path_peak[file, 2],&quot;_&quot;,y,&quot;_GCVI.tif&quot;), # scale = 10) # } # } 2.2 Clean yield monitor data The methodology to be used in this case for cleaning yield monitor maps is that used by Cordoba et al. (2009). This methodology consists of two steps: removing outliers and cleaning according to the Local Moran Method. Delete outliers: This involves removing yield values that are more than three standard deviations above or below the mean. In this step, global outliers located at the extremes of the dataset are eliminated, but not local extremes (spatial outliers). Local Moran: This step involves eliminating spatial outliers, also known as inliers, which are data points that significantly differ from their neighborhood but are within the general range of variation of the dataset. This inlier identification step is based on Anselin (1995) methodology, known as the local Moran’s spatial autocorrelation index. Given a group of data belonging to different neighborhoods, Local Moran is applied to each data point individually, indicating the degree of similarity or difference between the value of an observation and the values of its neighbors. To calculate the Moran’s Index, it is necessary to identify the neighborhood for each data point, which is the domain where there are data that can be interpreted as spatial neighbors and will be used as a reference to determine whether the data point is different from its neighbors. Source: https://www.researchgate.net/profile/Monica-Balzarini/publication/341282116_Guia_para_el_analisis_de_datos_espaciales_Aplicaciones_en_agricultura/links/5f4e253fa6fdcc14c505fedd/Guia-para-el-analisis-de-datos-espaciales-Aplicaciones-en-agricultura.pdf” 2.2.1 Import libraries # Packages to be used library_names &lt;- c(&quot;sp&quot;, # (Bivand et al., 2012) &quot;sf&quot;, # (Pebesma, 2018) &quot;spdep&quot;, # local moran (Pebesma and Bivand, 2023) &quot;gstat&quot;, # grid and interpolation (Gräler et al., 2016) &quot;raster&quot;, # (Hijmans, 2023) &quot;chirps&quot;, # (Funk et al., 2015) &quot;tidyverse&quot;) # (Wickham et al., 2019) # Iterate over each library name for (lib_name in library_names) { # Check if the library is already installed if (!require(lib_name, character.only = TRUE)) { # If the library is not installed, install it install.packages(lib_name, dependencies = TRUE) # Load the library library(lib_name, character.only = TRUE) } else { # If the library is already installed, load it library(lib_name, character.only = TRUE) } } 2.2.2 Field identification Add the name of the field that you want to clean below. The code is all related to the name that you add there. FIELD_TO_CLEAN &lt;- &quot;OH2&quot; 2.2.3 Cleaning process Obtain path to original Yield monitor data To automate the cleaning process, establish paths for: (i) each yield monitor data file that requires cleaning, and (ii) the field polygon. The field polygon will be used to cut the yield map, allowing for the exclusion of data collected when the harvesting machine is maneuvering around field borders and other problematic areas. IMPORTANT: After running the entire cleaning code, and maybe (could help to visualize) the data exploration code, check the yield distribution within the field. If there is strange patterns or some rows with completely different yields, check the data in QGIS to evaluate it there is any problem. files &lt;- data.frame( path = list.files(c(paste0(&quot;1_Data/3_YM/1_Original/&quot;,FIELD_TO_CLEAN,&quot;/Soybean&quot;), paste0(&quot;1_Data/3_YM/1_Original/&quot;,FIELD_TO_CLEAN,&quot;/Maize&quot;)), full.names = T, pattern = &quot;.shp&quot;, recursive = T)) %&gt;% mutate(Polygon =list.files(&quot;1_Data/1_Polygon&quot;, pattern = paste0(FIELD_TO_CLEAN,&quot;_pol.shp&quot;), full.names = T, recursive = T)) %&gt;% mutate(path2=path) %&gt;% separate(col = path2, into = c(&quot;del_Datafold&quot; ,&quot;del_YMfold&quot;,&quot;del_Origfold&quot; ,&quot;Field&quot;, &quot;Crop&quot;, &quot;Farm_name&quot;), sep = &quot;/&quot;) %&gt;% separate(col = Farm_name, into = c(&quot;Family&quot;, &quot;del_Home&quot;, &quot;del_field&quot;, &quot;del_harvest&quot;, &quot;Year&quot;), sep = &quot;_&quot;) %&gt;% mutate(Year = as.numeric(gsub(&quot;.*_(20\\\\d{2})-.*\\\\.shp&quot;, &quot;\\\\1&quot;, path)))%&gt;% dplyr::filter(Year &gt;2015) %&gt;% dplyr::select(-c(starts_with(&quot;del_&quot;))) 1) Check data &amp; first step of cleaning process This code first generates yield maps before any cleaning process is applied. Next, it performs the initial step of the cleaning process by removing extreme outliers. This is done by filtering the data based on combine speed, grain moisture, and yield variables. for (file in 1:nrow(files)){ ########################################################### #### DATA CHECKING #### ########################################################### # Obtain yield monitor data YM &lt;- read_sf(files[file,1]) %&gt;% st_set_crs(st_crs(&quot;epsg:4326&quot;)) %&gt;% st_transform(crs=32616) %&gt;% dplyr::mutate(X = as.numeric(sf::st_coordinates(.)[,1]), Y = as.numeric(sf::st_coordinates(.)[,2])) %&gt;% rename(Yield = VRYIELDVOL, VEHICLSPEED = starts_with(&quot;VEHICLSPE&quot;)) %&gt;% dplyr::select(Moisture,WetMass,Yield, VEHICLSPEED, DISTANCE) # Obtain Field polygon (boundary) pol &lt;- read_sf(files[file,2]) %&gt;% st_transform(crs = st_crs(YM)) # Clip the yield data with the field boundary YM &lt;- st_intersection(YM, pol) # Plot data to check original data YM_original &lt;- YM %&gt;% ggplot()+ geom_sf(aes(color = Yield))+ labs(color = &quot;Yield (bu/ac)&quot;)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;, &quot;#ffdc00&quot;,&quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ theme(axis.text = element_blank(), axis.ticks = element_blank()) ggsave(paste0(&quot;3_Output/2_YM_clean/1_Original/YM/&quot;, files[file,3],&quot;_&quot;,files[file,4],files[file,6],&quot;.png&quot;), height = 3, width = 6.5) distr_pl &lt;- YM %&gt;% dplyr::select(-FID) %&gt;% pivot_longer(!geometry, names_to = &quot;Var&quot;, values_to = &quot;Val&quot;) %&gt;% ggplot()+ geom_histogram(aes(Val), fill = &quot;grey60&quot;, color = &quot;grey20&quot;)+ facet_wrap(~Var, ncol = 1, scales = &quot;free&quot;)+ theme_bw()+ labs(x = &quot;Value&quot;)+ theme(strip.background = element_blank()) ggsave(paste0(&quot;3_Output/2_YM_clean/1_Original/Distr/&quot;, files[file,3],&quot;_&quot;,files[file,4],files[file,6],&quot;.png&quot;), height = 6, width = 2.5) ########################################################### #### DATA CLEANING: STEP 1 #### ########################################################### # 1) Remove general outliers (extreme outliers) YM_in &lt;- YM %&gt;% dplyr::filter(Yield&gt;=0) %&gt;% mutate(Speed_q025 = quantile(VEHICLSPEED, 0.025), Speed_q975 = quantile(VEHICLSPEED, 0.975), Moist_q025 = quantile(Moisture, 0.025), Moist_q975 = quantile(Moisture, 0.975), mean_yield = mean(Yield), sd_yield = sd(Yield), LI = mean_yield-3*sd_yield, LS = mean_yield+3*sd_yield) %&gt;% # Filtering rules with clear physical meaning dplyr::filter(Yield&gt; LI &amp; Yield&lt; LS &amp; VEHICLSPEED &gt; Speed_q025 &amp; VEHICLSPEED &lt;Speed_q975&amp; Moisture &gt; Moist_q025 &amp; Moisture &lt; Moist_q975) sf::write_sf(YM_in,paste0(&quot;1_Data/3_YM/2_Clean_Gener_Outliers/&quot;, FIELD_TO_CLEAN,&quot;_&quot;,files[file,4],&quot;_&quot;,files[file,6],&quot;.shp&quot;), append = FALSE) # Plot data with the first cleaning step YM_out &lt;- YM_in %&gt;% ggplot()+ geom_sf(aes(color = Yield))+ labs(color = &quot;Yield (bu/ac)&quot;)+ scale_color_gradientn(colors=c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;, &quot;#ffdc00&quot;,&quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ theme(axis.text = element_blank(), axis.ticks = element_blank()) ggsave(paste0(&quot;3_Output/2_YM_clean/2_General_Outliers/&quot;, files[file,3],&quot;_&quot;,files[file,4],files[file,6],&quot;.png&quot;), height = 3, width = 6.5) } plot(YM_original) # Original data without removing general outliers plot(YM_out) # Yield monitor data without general outliers Path to Yield monitor without extreme/general outliers Upload the paths to the yield monitor data shapefiles after removing extreme outliers. Additionally, create a 10 m x 10 m grid for the farm to match the cell/pixel size of the Sentinel data. files2 &lt;-data.frame(path=list.files(&quot;1_Data/3_YM/2_Clean_Gener_Outliers&quot;, full.names = T,pattern = &quot;.shp&quot;,recursive =T)) %&gt;% dplyr::filter(str_detect(path, FIELD_TO_CLEAN)) %&gt;% mutate(Polygon = as.vector(list.files(&quot;1_Data/1_Polygon&quot;, full.names = T, pattern = paste0(FIELD_TO_CLEAN,&quot;_pol.shp&quot;), recursive = T)), path2=path) %&gt;% mutate(path2 = str_remove(path2,paste0(&quot;1_Data/3_YM/2_Clean_Gener_Outliers/&quot;, FIELD_TO_CLEAN,&quot;_&quot;)), Field = FIELD_TO_CLEAN) %&gt;% separate(col = path2, into = c(&quot;Crop&quot;, &quot;Year&quot;), sep = &quot;_&quot;) %&gt;% mutate(Year = str_remove(Year, &quot;.shp&quot;)) # This part is to obtain the field boundaries YM &lt;- YM_in%&gt;% dplyr::mutate(X = as.numeric(sf::st_coordinates(.)[,1]), Y = as.numeric(sf::st_coordinates(.)[,2])) %&gt;% dplyr::select(X,Y,Yield) %&gt;% st_drop_geometry() %&gt;% as.data.frame() names(YM) &lt;- c(&quot;X&quot;, &quot;Y&quot;,&quot;Yield&quot;) coordinates(YM) &lt;- c(&quot;X&quot;, &quot;Y&quot;) proj4string(YM) &lt;- CRS(&quot;+proj=utm +zone=16 +datum=WGS84 +units=m +no_defs&quot;) grd &lt;- expand.grid(x = seq(min(as.data.frame(YM)[,1]), max(as.data.frame(YM)[,1]), by=10), y = seq(min(as.data.frame(YM)[,2]), max(as.data.frame(YM)[,2]), by=10)) names(grd) &lt;- c(&quot;X&quot;,&quot;Y&quot;) coordinates(grd) &lt;- c(&quot;X&quot;,&quot;Y&quot;) proj4string(grd) &lt;-CRS(&quot;+proj=utm +zone=16 +datum=WGS84 +units=m +no_defs&quot;) gridded(grd) &lt;- TRUE # Create SpatialPixel object fullgrid(grd) &lt;- TRUE # Create SpatialGrid object 2) Second step of cleaning yield monitor data: Local Moran Second step of the data cleaning process: The Local Moran method was used to identify and remove inliers and spatial outliers from the dataset. Additionally, yield monitor data were interpolated using inverse distance weighting (IDW) interpolation (Gräler et al., 2016) to generate a 10x10 m grid. This grid resolution allows for the consistent overlay of yield monitor data across multiple years and aligns with the resolution of Sentinel data. for (file in 1:nrow(files2)){ ########################################################### #### DATA CLEANING: STEP 2 #### ########################################################### # Upload dataframe without extreme values YM_in &lt;- read_sf(files2[file,1]) ## LOCAL MORAN CLEANING METHOD ## NB &lt;- dnearneigh(YM_in$geometry, d1 = 0, d2 = 18) #summary(NB) moranl &lt;-localmoran(YM_in$Yield, nb2listw(NB,style = &quot;W&quot;), alternative = &quot;less&quot;) moranp &lt;- moran.plot(YM_in$Yield, col = 3, nb2listw(NB,style = &quot;W&quot;), labels = F,quiet = T, xlab = &quot;Rinde&quot;, ylab = &quot;Rinde Spatially Lagged&quot;) #summary(moranp) influ &lt;- moranp$is_inf data &lt;- cbind(YM_in, moranl, influ) # Obtain dataset without extreme and spatial outliers YM_clean &lt;-subset(data, data[[&quot;Ii&quot;]] &gt;= 0 | data[[&quot;Pr.z...E.Ii..&quot;]] &gt; 0.05) inliers_ml &lt;-subset(data, data[[&quot;Ii&quot;]] &lt; 0 &amp; data[[&quot;Pr.z...E.Ii..&quot;]] &lt; 0.05) # Plot to check data YM_clean_pl &lt;- YM_clean %&gt;% ggplot()+ geom_sf(aes(color = Yield))+ labs(color = &quot;Yield (bu/ac)&quot;)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;, &quot;#ffdc00&quot;,&quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ theme(axis.text = element_blank(), axis.ticks = element_blank()) ggsave(paste0(&quot;3_Output/2_YM_clean/3_Local_Moran/&quot;, files2[file,5],&quot;_&quot;,files2[file,3],files2[file,4],&quot;.png&quot;), height = 3, width = 6.5) ########################################################### #### CREATE GRID &amp; INTERPOLATE #### ########################################################### # Yield data YM &lt;- YM_clean %&gt;% dplyr::mutate(X = as.numeric(sf::st_coordinates(.)[,1]), Y = as.numeric(sf::st_coordinates(.)[,2])) %&gt;% dplyr::select(X,Y,Yield) %&gt;% st_drop_geometry() %&gt;% as.data.frame() names(YM) &lt;- c(&quot;X&quot;, &quot;Y&quot;,&quot;Yield&quot;) coordinates(YM) &lt;- c(&quot;X&quot;, &quot;Y&quot;) proj4string(YM) &lt;- CRS(&quot;+proj=utm +zone=16 +datum=WGS84 +units=m +no_defs&quot;) # Create grid using the field polygon pol &lt;- read_sf(files2[file,2]) %&gt;% st_transform(crs = st_crs(YM)) # Interpolation idw &lt;- idw(formula = YM$Yield~1, locations = YM, newdata = grd, idp =3) %&gt;% raster::raster() idw &lt;- raster::mask(idw, pol) raster::writeRaster(idw, paste0(&quot;1_Data/3_YM/3_Interp_Grid/&quot;, files2[file,5],&quot;_&quot;,files2[file,3],files2[file,4], &quot;.tif&quot;), overwrite = T) } plot(YM_clean_pl) # Yield monitor data cleaned mapview::mapview(idw) # Yield monitor data interpolateed &amp; gridded 3) Join all years of yield monitor data Up to this point, we have separate shapefiles for each year and field. In this code, we are merging all the yearly shapefiles (containing the cleaned yield monitor data) for each field into a single shapefile. # Generate a dataframe with paths and metadata raster_paths &lt;- data.frame(path = list.files(&quot;1_Data/3_YM/3_Interp_Grid/&quot;, full.names = T,recursive = T, pattern = &quot;\\\\.tif$&quot;)) %&gt;% dplyr::filter(str_detect(path, FIELD_TO_CLEAN)) %&gt;% mutate(filename = basename(path), filename = str_remove(filename, paste0(FIELD_TO_CLEAN,&quot;_&quot;)), filename = str_remove(filename, &quot;\\\\.tif$&quot;)) %&gt;% separate(filename,into = c(&quot;Crop&quot;,&quot;Year&quot;),sep =&quot;(?&lt;=[A-Za-z])(?=[0-9])&quot;) %&gt;% arrange(Crop, Year) # Function to load raster read_rasters &lt;- function(x) { raster(x) } # Read and stack rasters raster_stack &lt;- raster_paths$path %&gt;% map(read_rasters) %&gt;% stack() YM_final &lt;- rasterToPoints(raster_stack, spatial=TRUE) %&gt;% st_as_sf() %&gt;% pivot_longer(!geometry, names_to = &quot;CropYear&quot;, values_to = &quot;Yield&quot;) %&gt;% mutate(CropYear = str_remove(CropYear, paste0(FIELD_TO_CLEAN,&quot;_&quot;))) %&gt;% st_transform(crs=32616) %&gt;% dplyr::mutate(X = as.numeric(sf::st_coordinates(.)[,1]), Y = as.numeric(sf::st_coordinates(.)[,2])) %&gt;% separate(CropYear, into = c(&quot;Crop&quot;, &quot;Year&quot;), sep = &quot;(?&lt;=[A-Za-z])(?=[0-9])&quot;) %&gt;% mutate(Year = as.numeric(Year)) write_sf(YM_final,paste0(&quot;1_Data/3_YM/4_YM_final/YM_&quot;,FIELD_TO_CLEAN,&quot;.shp&quot;)) 2.2.4 Merge YM data &amp; GCVI data Path to rasters (Sentinel data) and clean yield monitor data Obtain the file paths for each field image where the GCVI has already been calculated. These images correspond to three key moments: the peak, 30 days before the peak (Peak_b3), and 30 days after the peak (Peak_30). vi_path &lt;- data.frame(path =list.files(c(&quot;1_Data/2_Spatial_Layer/2_VI_raster/Peak_b3/&quot;, &quot;1_Data/2_Spatial_Layer/2_VI_raster/Peak/&quot;, &quot;1_Data/2_Spatial_Layer/2_VI_raster/Peak_30/&quot;), full.names=T, pattern= &quot;.tif&quot;, recursive = T)) %&gt;% mutate(YM_path =list.files(&quot;1_Data/3_YM/4_YM_final&quot;, full.names=T,recursive = TRUE, pattern=paste0(FIELD_TO_CLEAN,&quot;.shp&quot;))) %&gt;% mutate(Year = gsub(&quot;.*_(20\\\\d{2})_.*\\\\.tif&quot;, &quot;\\\\1&quot;, path), Moment = str_extract(path, &quot;(?&lt;=2_VI_raster/)[^/]+(?=/)&quot;), VI = str_extract(path, &quot;(NDVI|EVI|GCVI)&quot;), VI_moment = paste(Moment,VI,sep = &quot;_&quot;)) %&gt;% dplyr::filter(str_detect(path, FIELD_TO_CLEAN)) %&gt;% pivot_wider(names_from = Year, values_from = path) %&gt;% dplyr::filter(VI == &quot;GCVI&quot;) Join all rasters to a dataframe Overlay all the rasters containing GCVI data for the field and clip them using the field boundary. Additionally, extract the relevant information from the rasters. VImoments &lt;- c(unique(vi_path$VI_moment)) for (VIm in VImoments) { viPath &lt;- vi_path %&gt;% dplyr::filter(VI_moment == VIm) YM &lt;- read_sf(viPath[1][[1]]) %&gt;% st_transform(&quot;epsg:4326&quot;) points &lt;- YM %&gt;% st_centroid() str_crs &lt;- &quot;+init=epsg:4326&quot; y17 &lt;-raster(viPath[5][[1]]) crs(y17) &lt;- str_crs names(y17) &lt;- &quot;2017&quot; y18 &lt;-raster(viPath[6][[1]]) crs(y18) &lt;- str_crs names(y18) &lt;- &quot;2018&quot; y19 &lt;-raster(viPath[7][[1]]) crs(y19) &lt;- str_crs names(y19) &lt;- &quot;2019&quot; y20 &lt;-raster(viPath[8][[1]]) crs(y20) &lt;- str_crs names(y20) &lt;- &quot;2020&quot; y21 &lt;-raster(viPath[9][[1]]) crs(y21) &lt;- str_crs names(y21) &lt;- &quot;2021&quot; y22 &lt;-raster(viPath[10][[1]]) crs(y22) &lt;- str_crs names(y22) &lt;- &quot;2022&quot; y23 &lt;-raster(viPath[11][[1]]) crs(y23) &lt;- str_crs names(y23) &lt;- &quot;2023&quot; ## Stack/overlap the layers layers_stacked &lt;- raster::stack(y17,y18,y19,y20,y21,y22,y23) data_extracted &lt;- raster::extract(layers_stacked, points, fun=&#39;median&#39;, df=TRUE) %&gt;% tibble::rownames_to_column(var = &quot;Iden&quot;) merge &lt;- bind_cols(points, data_extracted) %&gt;% st_drop_geometry() %&gt;% st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;)) %&gt;% pivot_longer(starts_with(&quot;X20&quot;),names_to = &quot;year_VI&quot;, values_to = VIm) %&gt;% mutate(year_VI = as.numeric(str_remove(year_VI, &quot;X&quot;))) %&gt;% dplyr::filter(Year == year_VI) %&gt;% dplyr::select(Crop, Year, Yield, starts_with(VIm),geometry) write_sf(merge,paste0(&quot;1_Data/2_Spatial_Layer/4_VI_YM/&quot;,FIELD_TO_CLEAN,&quot;_&quot;,VIm,&quot;.shp&quot;)) } Join yield monitor data and GCVI data Merge the satellite data (GCVI at the peak, 30 days before, and 30 days after) with the yield monitor data across multiple years. # Base directory and field specifics base_dir &lt;- &quot;1_Data/2_Spatial_Layer/4_VI_YM/&quot; indices &lt;- &quot;GCVI&quot; moments &lt;- c(&quot;_b3&quot;,&quot;&quot;,&quot;_30&quot;) # Initial data load and filtering main_data &lt;- read_sf(paste0(&quot;1_Data/3_YM/4_YM_final/YM_&quot;,FIELD_TO_CLEAN,&quot;.shp&quot;)) %&gt;% filter(Year &gt; 2016) # Loop over moments and indices for (moment in moments) { for (vi in indices) { file_path &lt;- paste0(base_dir, FIELD_TO_CLEAN, &quot;_Peak&quot;, moment, &quot;_&quot;, vi, &quot;.shp&quot;) shape_data &lt;- read_sf(file_path) %&gt;% st_set_crs(4326) %&gt;% mutate(X = as.numeric(st_coordinates(.)[, 1]), Y = as.numeric(st_coordinates(.)[, 2])) %&gt;% st_drop_geometry() %&gt;% as.data.frame() main_data &lt;- left_join(main_data,shape_data,by = c(&quot;Year&quot;,&quot;X&quot;,&quot;Y&quot;,&quot;Crop&quot;,&quot;Yield&quot;)) } } main_data &lt;- main_data %&gt;% dplyr::select(Crop, Year, Yield, X,Y, starts_with(&quot;P&quot;)) %&gt;% rename(Crop = Crop) sf::write_sf(main_data, paste0(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/&quot;,FIELD_TO_CLEAN,&quot;.shp&quot;)) # Check the final output #print(main_data) 2.3 CP period Obtain daily precipitation data from CHIRPS datasets. Then, calculate different periods of cumulative precipitation. ## Path to the field to obtain the location/coordinates ## path &lt;- data.frame(path = as.vector(list.files(paste0(&quot;1_Data/3_YM/1_Original/&quot;,FIELD_TO_CLEAN,&quot;/Maize&quot;), full.names = T, pattern = &quot;.shp&quot;, recursive = T))) %&gt;% dplyr::filter(row_number()==1) ## Identify range of years with data available in that field ## start_Year &lt;- min(unique(main_data$Year)) end_Year &lt;- max(unique(main_data$Year)) ## Download daily precipitation data ## pp_chirps &lt;- get_chirps(read_sf(path) %&gt;%dplyr::filter(row_number() == 1), dates = c(paste0(start_Year,&quot;-01-01&quot;), paste0(end_Year,&quot;-12-31&quot;)), server = &quot;ClimateSERV&quot;) %&gt;% as.data.frame() %&gt;% mutate(doy = yday(date), month = month(date), Year = year(date)) ## Fetching data from ClimateSERV ## Getting your request... ## Calculate different cumulative precipitation periods ## CP_period &lt;- YM_final %&gt;% dplyr::select(Year) %&gt;% st_drop_geometry() %&gt;% distinct() %&gt;% left_join(pp_chirps, by = &quot;Year&quot;) %&gt;% dplyr::filter(Year&gt;2016) %&gt;% group_by(Year) %&gt;% nest() %&gt;% mutate( ## April 1 ## CRA1_180 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 180) &amp; doy &gt; 90) %&gt;% summarise(CRA1_180 = max(cumsum(chirps)))), CRA1_170 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 170) &amp; doy &gt; 90) %&gt;% summarise(CRA1_170 = max(cumsum(chirps)))), CRA1_160 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 160) &amp; doy &gt; 90) %&gt;% summarise(CRA1_160 = max(cumsum(chirps)))), CRA1_150 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 150) &amp; doy &gt; 90) %&gt;% summarise(CRA1_150 = max(cumsum(chirps)))), CRA1_140 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 140) &amp; doy &gt; 90) %&gt;% summarise(CRA1_140 = max(cumsum(chirps)))), CRA1_130 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 130) &amp; doy &gt; 90) %&gt;% summarise(CRA1_130 = max(cumsum(chirps)))), CRA1_120 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 120) &amp; doy &gt; 90) %&gt;% summarise(CRA1_120 = max(cumsum(chirps)))), CRA1_110 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 110) &amp; doy &gt; 90) %&gt;% summarise(CRA1_110 = max(cumsum(chirps)))), CRA1_100 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 100) &amp; doy &gt; 90) %&gt;% summarise(CRA1_100 = max(cumsum(chirps)))), CRA1_90 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 90) &amp; doy &gt; 90) %&gt;% summarise(CRA1_90 = max(cumsum(chirps)))), CRA1_80 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 80) &amp; doy &gt; 90) %&gt;% summarise(CRA1_80 = max(cumsum(chirps)))), CRA1_70 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 70) &amp; doy &gt; 90) %&gt;% summarise(CRA1_70 = max(cumsum(chirps)))), CRA1_60 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 60) &amp; doy &gt; 90) %&gt;% summarise(CRA1_60 = max(cumsum(chirps)))), CRA1_50 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 50) &amp; doy &gt; 90) %&gt;% summarise(CRA1_50 = max(cumsum(chirps)))), CRA1_40 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 40) &amp; doy &gt; 90) %&gt;% summarise(CRA1_40 = max(cumsum(chirps)))), CRA1_30 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 30) &amp; doy &gt; 90) %&gt;% summarise(CRA1_30 = max(cumsum(chirps)))), CRA1_20 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 20) &amp; doy &gt; 90) %&gt;% summarise(CRA1_20 = max(cumsum(chirps)))), CRA1_10 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (90 + 10) &amp; doy &gt; 90) %&gt;% summarise(CRA1_10 = max(cumsum(chirps)))), ## April 10## CRA2_180 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 180) &amp; doy &gt; 99) %&gt;% summarise(CRA2_180 = max(cumsum(chirps)))), CRA2_170 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 170) &amp; doy &gt; 99) %&gt;% summarise(CRA2_170 = max(cumsum(chirps)))), CRA2_160 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 160) &amp; doy &gt; 99) %&gt;% summarise(CRA2_160 = max(cumsum(chirps)))), CRA2_150 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 150) &amp; doy &gt; 99) %&gt;% summarise(CRA2_150 = max(cumsum(chirps)))), CRA2_140 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 140) &amp; doy &gt; 99) %&gt;% summarise(CRA2_140 = max(cumsum(chirps)))), CRA2_130 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 130) &amp; doy &gt; 99) %&gt;% summarise(CRA2_130 = max(cumsum(chirps)))), CRA2_120 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 120) &amp; doy &gt; 99) %&gt;% summarise(CRA2_120 = max(cumsum(chirps)))), CRA2_110 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 110) &amp; doy &gt; 99) %&gt;% summarise(CRA2_110 = max(cumsum(chirps)))), CRA2_100 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 100) &amp; doy &gt; 99) %&gt;% summarise(CRA2_100 = max(cumsum(chirps)))), CRA2_90 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 90) &amp; doy &gt; 99) %&gt;% summarise(CRA2_90 = max(cumsum(chirps)))), CRA2_80 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 80) &amp; doy &gt; 99) %&gt;% summarise(CRA2_80 = max(cumsum(chirps)))), CRA2_70 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 70) &amp; doy &gt; 99) %&gt;% summarise(CRA2_70 = max(cumsum(chirps)))), CRA2_60 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 60) &amp; doy &gt; 99) %&gt;% summarise(CRA2_60 = max(cumsum(chirps)))), CRA2_50 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 50) &amp; doy &gt; 99) %&gt;% summarise(CRA2_50 = max(cumsum(chirps)))), CRA2_40 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 40) &amp; doy &gt; 99) %&gt;% summarise(CRA2_40 = max(cumsum(chirps)))), CRA2_30 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 30) &amp; doy &gt; 99) %&gt;% summarise(CRA2_30 = max(cumsum(chirps)))), CRA2_20 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 20) &amp; doy &gt; 99) %&gt;% summarise(CRA2_20 = max(cumsum(chirps)))), CRA2_10 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (99 + 10) &amp; doy &gt; 99) %&gt;% summarise(CRA2_10 = max(cumsum(chirps)))), ## April 20## CRA3_180 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 180) &amp; doy &gt; 109) %&gt;% summarise(CRA3_180 = max(cumsum(chirps)))), CRA3_170 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 170) &amp; doy &gt; 109) %&gt;% summarise(CRA3_170 = max(cumsum(chirps)))), CRA3_160 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 160) &amp; doy &gt; 109) %&gt;% summarise(CRA3_160 = max(cumsum(chirps)))), CRA3_150 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 150) &amp; doy &gt; 109) %&gt;% summarise(CRA3_150 = max(cumsum(chirps)))), CRA3_140 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 140) &amp; doy &gt; 109) %&gt;% summarise(CRA3_140 = max(cumsum(chirps)))), CRA3_130 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 130) &amp; doy &gt; 109) %&gt;% summarise(CRA3_130 = max(cumsum(chirps)))), CRA3_120 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 120) &amp; doy &gt; 109) %&gt;% summarise(CRA3_120 = max(cumsum(chirps)))), CRA3_110 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 110) &amp; doy &gt; 109) %&gt;% summarise(CRA3_110 = max(cumsum(chirps)))), CRA3_100 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 100) &amp; doy &gt; 109) %&gt;% summarise(CRA3_100 = max(cumsum(chirps)))), CRA3_90 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 90) &amp; doy &gt; 109) %&gt;% summarise(CRA3_90 = max(cumsum(chirps)))), CRA3_80 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 80) &amp; doy &gt; 109) %&gt;% summarise(CRA3_80 = max(cumsum(chirps)))), CRA3_70 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 70) &amp; doy &gt; 109) %&gt;% summarise(CRA3_70 = max(cumsum(chirps)))), CRA3_60 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 60) &amp; doy &gt; 109) %&gt;% summarise(CRA3_60 = max(cumsum(chirps)))), CRA3_50 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 50) &amp; doy &gt; 109) %&gt;% summarise(CRA3_50 = max(cumsum(chirps)))), CRA3_40 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 40) &amp; doy &gt; 109) %&gt;% summarise(CRA3_40 = max(cumsum(chirps)))), CRA3_30 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 30) &amp; doy &gt; 109) %&gt;% summarise(CRA3_30 = max(cumsum(chirps)))), CRA3_20 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 20) &amp; doy &gt; 109) %&gt;% summarise(CRA3_20 = max(cumsum(chirps)))), CRA3_10 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (109 + 10) &amp; doy &gt; 109) %&gt;% summarise(CRA3_10 = max(cumsum(chirps)))), ## May 1## CRM1_180 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 180) &amp; doy &gt; 120) %&gt;% summarise(CRM1_180 = max(cumsum(chirps)))), CRM1_170 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 170) &amp; doy &gt; 120) %&gt;% summarise(CRM1_170 = max(cumsum(chirps)))), CRM1_160 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 160) &amp; doy &gt; 120) %&gt;% summarise(CRM1_160 = max(cumsum(chirps)))), CRM1_150 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 150) &amp; doy &gt; 120) %&gt;% summarise(CRM1_150 = max(cumsum(chirps)))), CRM1_140 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 140) &amp; doy &gt; 120) %&gt;% summarise(CRM1_140 = max(cumsum(chirps)))), CRM1_130 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 130) &amp; doy &gt; 120) %&gt;% summarise(CRM1_130 = max(cumsum(chirps)))), CRM1_120 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 120) &amp; doy &gt; 120) %&gt;% summarise(CRM1_120 = max(cumsum(chirps)))), CRM1_110 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 110) &amp; doy &gt; 120) %&gt;% summarise(CRM1_110 = max(cumsum(chirps)))), CRM1_100 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 100) &amp; doy &gt; 120) %&gt;% summarise(CRM1_100 = max(cumsum(chirps)))), CRM1_90 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 90) &amp; doy &gt; 120) %&gt;% summarise(CRM1_90 = max(cumsum(chirps)))), CRM1_80 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 80) &amp; doy &gt; 120) %&gt;% summarise(CRM1_80 = max(cumsum(chirps)))), CRM1_70 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 70) &amp; doy &gt; 120) %&gt;% summarise(CRM1_70 = max(cumsum(chirps)))), CRM1_60 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 60) &amp; doy &gt; 120) %&gt;% summarise(CRM1_60 = max(cumsum(chirps)))), CRM1_50 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 50) &amp; doy &gt; 120) %&gt;% summarise(CRM1_50 = max(cumsum(chirps)))), CRM1_40 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 40) &amp; doy &gt; 120) %&gt;% summarise(CRM1_40 = max(cumsum(chirps)))), CRM1_30 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 30) &amp; doy &gt; 120) %&gt;% summarise(CRM1_30 = max(cumsum(chirps)))), CRM1_20 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 20) &amp; doy &gt; 120) %&gt;% summarise(CRM1_20 = max(cumsum(chirps)))), CRM1_10 = data %&gt;% map(.,~as.data.frame(data) %&gt;% dplyr::filter(doy &lt; (120 + 10) &amp; doy &gt; 120) %&gt;% summarise(CRM1_10 = max(cumsum(chirps)))) ) %&gt;% unnest(starts_with(&quot;CR&quot;)) %&gt;% pivot_longer(starts_with(&quot;CR&quot;), names_to = &quot;Period&quot;, values_to = &quot;CR&quot;) %&gt;% separate(Period, c(&quot;Start_moment&quot;, &quot;Period&quot;),sep = &quot;_&quot;) %&gt;% mutate(Start_moment = str_remove(Start_moment, &quot;CR&quot;), Start_moment = case_when(Start_moment == &quot;A1&quot; ~ &quot;April-1&quot;, Start_moment == &quot;A2&quot; ~ &quot;April-10&quot;, Start_moment == &quot;A3&quot; ~ &quot;April-20&quot;, Start_moment == &quot;M1&quot; ~ &quot;May-1&quot;, Start_moment == &quot;M2&quot; ~ &quot;May-10&quot;, TRUE ~&quot;NA&quot;), CR = round(CR, 1)) %&gt;% dplyr::select(-data) write.csv(CP_period, paste0(&quot;1_Data/4_CP/CP_&quot;,FIELD_TO_CLEAN,&quot;.csv&quot;), row.names = F) 2.4 Data exploration ######## ADD FIELD NAME. Example: OH2 or IL3 ########## ##### CHANGE THE NAME BETWEEN THE QUOTATION MARKS ##### FIELD_NAME &lt;- &quot;IL5&quot; Upload the data YM_VI_df &lt;- read_sf(paste0(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/&quot;,FIELD_NAME,&quot;.shp&quot;)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id()) %&gt;% pivot_longer(cols = starts_with(&quot;P&quot;), names_to = &quot;Moment&quot;, values_to = &quot;VIm_val&quot;) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25), VI = case_when(str_detect(Moment, &quot;GC&quot;) ~ &quot;GCVI&quot;, str_detect(Moment, &quot;ND&quot;) ~ &quot;NDVI&quot;, str_detect(Moment, &quot;EV&quot;) ~ &quot;EVI&quot;), Moment = case_when(str_detect(Moment, &quot;3_&quot;) ~ -30, str_detect(Moment, &quot;30&quot;) ~ 30, TRUE ~ 0)) Plot: Yield &amp; VI maps per year &amp; crop Plot the yield data alongside GCVI values from 30 days before the peak, at the peak, and 30 days after the peak across multiple years to observe whether yield patterns can be identified using satellite data. maize_ym &lt;- YM_VI_df %&gt;% dplyr::filter(Crop == &quot;Maize&quot; &amp; Moment == 0 &amp; VI == &quot;GCVI&quot;) %&gt;% ggplot()+ geom_sf(aes(color = Yield),size=1)+ facet_wrap(~Year, nro = 1)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;,&quot;#ffdc00&quot;,&quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ theme(axis.text = element_blank(), axis.ticks = element_blank(), strip.background = element_blank(),strip.text = element_text(size = 10), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;right&quot;, legend.text = element_text(size = 9), legend.key.height= unit(.5, &#39;cm&#39;), legend.key.width= unit(.2, &#39;cm&#39;)) maize_b30 &lt;- YM_VI_df %&gt;% dplyr::filter(Crop == &quot;Maize&quot; &amp; Moment == -30 &amp; VI == &quot;GCVI&quot;) %&gt;% ggplot()+ geom_sf(aes(color = VIm_val),size=1)+ facet_wrap(~Year, nrow = 1)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;,&quot;#ffdc00&quot;,&quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ labs(color = &quot;Peak-30&quot;)+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ theme(axis.text = element_blank(), axis.ticks = element_blank(), strip.background = element_blank(), strip.text = element_text(size = 10), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;right&quot;, legend.text = element_text(size = 8), legend.key.height= unit(.5, &#39;cm&#39;), legend.key.width= unit(.2, &#39;cm&#39;)) maize_p &lt;- YM_VI_df %&gt;% dplyr::filter(Crop == &quot;Maize&quot; &amp; Moment == 0 &amp; VI == &quot;GCVI&quot;) %&gt;% ggplot()+ geom_sf(aes(color = VIm_val),size=1)+ facet_wrap(~Year, nrow = 1)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;,&quot;#ffdc00&quot;, &quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ labs(color = &quot;Peak-00&quot;)+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ theme(axis.text = element_blank(), axis.ticks = element_blank(), strip.background = element_blank(), strip.text = element_text(size = 10), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;right&quot;, legend.text = element_text(size = 8), legend.key.height= unit(.5, &#39;cm&#39;), legend.key.width= unit(.2, &#39;cm&#39;)) maize_30 &lt;- YM_VI_df %&gt;% dplyr::filter(Crop == &quot;Maize&quot; &amp; Moment == 30 &amp; VI == &quot;GCVI&quot;) %&gt;% ggplot()+ geom_sf(aes(color = VIm_val),size=1)+ facet_wrap(~Year, nrow = 1)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;,&quot;#ffdc00&quot;,&quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;))+ labs(color = &quot;Peak+30&quot;)+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ theme(axis.text = element_blank(), axis.ticks = element_blank(), strip.background = element_blank(), strip.text = element_text(size = 10), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;right&quot;, legend.text = element_text(size = 8), legend.key.height= unit(.5, &#39;cm&#39;), legend.key.width= unit(.2, &#39;cm&#39;)) maize_map &lt;- cowplot::plot_grid(maize_ym, maize_b30, maize_p,maize_30, ncol = 1) plot(maize_map) ggsave(paste0(&quot;3_Output/3_Data_exploration/&quot;,FIELD_NAME,&quot;_maize_map.png&quot;), height = 9, width = 7) Plot: Yield vs GCVI Plot yield as a function of GCVI values at the three selected moments. maize_VIYM &lt;- YM_VI_df %&gt;% dplyr::filter(Crop == &quot;Maize&quot; ) %&gt;% ggplot()+ geom_point(aes(x = VIm_val, y = Yield, fill =as.factor(Year)), shape = 21, size =2, alpha =.4, show.legend = T) + facet_wrap(~Moment, scales = &quot;free_x&quot;, ncol = 1)+ labs(fill = &quot;Year&quot;)+ theme_bw()+ theme(strip.background = element_blank(), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), panel.grid.minor = element_blank(), axis.text = element_text(size = 7), axis.title.y = element_text(size = 10), axis.title.x = element_blank(), axis.ticks.length=unit(-0.1, &quot;cm&quot;)) plot(maize_VIYM) ggsave(paste0(&quot;3_Output/3_Data_exploration/&quot;,FIELD_NAME,&quot;_maize_VIYM.png&quot;),height = 8, width = 4) 2.5 Split field in training-testing Upload all the field shapefiles. For the dataset used to train the model, perform random sampling to ensure an equal number of points/pixels for each field-year. #################### TRAINING DATASET ############################# train_df &lt;- read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS2.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS2&quot;) %&gt;% ungroup() %&gt;% drop_na() %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS3.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS3&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS7.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS7&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS5.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS5&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/IL2.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;IL2&quot;) %&gt;% ungroup() %&gt;% dplyr::filter(Year %in% c(2020,2022)) %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/IL3.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;IL3&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/IL1.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;IL1&quot;) %&gt;% ungroup() %&gt;% dplyr::filter(Year %in% c(2017,2019)) %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/IA1.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;IA1&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/IL4.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;IL4&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS1.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS1&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS4.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS4&quot;) %&gt;% ungroup()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/KS6.shp&quot;) %&gt;% group_by(X,Y) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;KS6&quot;) %&gt;% drop_na() %&gt;% ungroup()) %&gt;% dplyr::filter(Crop == &quot;Maize&quot;) %&gt;% mutate(Yield = round(Yield)) %&gt;% dplyr::select(Farm, X, Y, ID, Crop, Year, Yield,Peak_GCVI, starts_with(&quot;P&quot;), starts_with(&quot;T&quot;), starts_with(&quot;DPV&quot;)) %&gt;% drop_na() ## Obtain same number of pixel per field randomly set.seed(8) train_sample &lt;- train_df %&gt;% group_by(Farm, Year) %&gt;% st_drop_geometry() %&gt;% nest() %&gt;% mutate(sample = map(data, ~ .x %&gt;% sample_n(size = 1200, replace = TRUE))) %&gt;% unnest(sample) %&gt;% dplyr::select(-data) %&gt;% ungroup() unique(train_sample$Farm) ## [1] &quot;KS2&quot; &quot;KS3&quot; &quot;KS7&quot; &quot;KS5&quot; &quot;IL2&quot; &quot;IL3&quot; &quot;IL1&quot; &quot;IA1&quot; &quot;IL4&quot; &quot;KS1&quot; &quot;KS4&quot; &quot;KS6&quot; ##################### TESTING DATASET ############################# test_df &lt;- read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/IL5.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;IL5&quot;) %&gt;% ungroup() %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/OH2.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;OH2&quot;) %&gt;% ungroup()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/NE1.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;NE1&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% bind_rows(read_sf(&quot;1_Data/2_Spatial_Layer/5_VI_YM_df/OH1.shp&quot;) %&gt;% rename(Crop = starts_with(&quot;Cr&quot;)) %&gt;% mutate(Yield = case_when(Crop == &quot;Maize&quot; ~ Yield * 62.77, Crop == &quot;Soybean&quot; ~ Yield * 67.25)) %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id(), Farm = &quot;OH1&quot;) %&gt;% ungroup() %&gt;% drop_na()) %&gt;% dplyr::filter(Crop == &quot;Maize&quot;) %&gt;% mutate(Yield = round(Yield)) 2.6 Reference Arno Z, Erickson J (2022). tidyrgee: ‘tidyverse’ Methods for ’Earth Engine’. R package version 0.1.0, https://CRAN.R-project.org/package=tidyrgee. Aybar C (2024). rgee: R Bindings for Calling the ‘Earth Engine’ API. https://github.com/r-spatial/rgee/, https://r-spatial.github.io/rgee/, https://github.com/google/earthengine-api/. Bivand R, Pebesma E, Gomez-Rubio V (2013). Applied spatial data analysis with R, Second edition. Springer, NY. https://asdar-book.org/. Córdoba, M.A., 2014. Herramientas estadísticas para el monitoreo y uso de la variabilidad espacial del rendimiento y propiedades de suelo intralote (Doctoral dissertation). Universidad Nacional de Córdoba. Funk, C., Peterson, P., Landsfeld, M., Pedreros, D., Verdin, J., Shukla, S., Husak, G., Rowland, J., Harrison, L., Hoell, A., Michaelsen, J., 2015. The climate hazards infrared precipitation with stations—a new environmental record for monitoring extremes. Sci Data 2, 150066. https://doi.org/10.1038/sdata.2015.66 Hijmans R (2023). raster: Geographic Data Analysis and Modeling. R package version 3.6-26, https://CRAN.R-project.org/package=raster. Pebesma E (2018). “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal, 10(1), 439–446. doi:10.32614/RJ-2018-009, https://doi.org/10.32614/RJ-2018-009. Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686. "],["yield-prediction-using-sentinel-2.html", "3 Yield prediction using sentinel-2 3.1 Import libraries 3.2 Model 3.3 Predict 3.4 Model evaluation 3.5 Save prediction 3.6 Reference", " 3 Yield prediction using sentinel-2 To upscale the assessment of spatio-temporal yield variation in relation to precipitation within a field, it is important to identify these patterns without relying solely on yield monitor data. This is crucial because not all farmers have access to many years of yield monitor data, yet this information is invaluable for optimizing field management. 3.1 Import libraries # Packages to be used library_names &lt;- c(&quot;sp&quot;, # (Bivand et al., 2012) &quot;sf&quot;, # (Pebesma, 2018) &quot;randomForest&quot;, #(Liaw and Wiener, 2002) &quot;rsample&quot;, # Select pixel randomly &quot;tidyverse&quot;) # (Wickham et al., 2019) # Iterate over each library name for (lib_name in library_names) { # Check if the library is already installed if (!require(lib_name, character.only = TRUE)) { # If the library is not installed, install it install.packages(lib_name, dependencies = TRUE) # Load the library library(lib_name, character.only = TRUE) } else { # If the library is already installed, load it library(lib_name, character.only = TRUE) } } 3.2 Model A random forest model was used to predict yield monitor data using the training dataset. Random forest, one of the most popular algorithms for yield prediction, is a machine learning technique used for estimating continuous response variables through regression analysis (Brieman, 2001). The model incorporates the Green Chlorophyll Vegetation Index (GCVI) at three key time points: the peak GCVI value, 30 days before the peak, and 30 days after the peak. The GCVI data were sourced from Sentinel-2, providing a pixel resolution of 10 m x 10 m within the field. m_rf &lt;- randomForest(Yield ~ P_3_GCV + Peak_GCVI + P_30_GC, data = train_sample) plot(m_rf) varImpPlot(m_rf) # m_rf #summary(m_rf) 3.3 Predict The testing data were used to generate model predictions and evaluate its performance. The testing dataset includes four fields: one field with four years of maize yield monitor data, and three others with one year of yield data each. These fields were separated from the training dataset. Most of the other fields in the training dataset are related geographically, as they are located on the same farm (e.g., fields in Kansas). In contrast, the testing fields are located in different regions than those used in the training dataset. rf_pred &lt;- test_df %&gt;% st_drop_geometry() %&gt;% mutate(year = Year) %&gt;% group_by(ID, year, Farm) %&gt;% nest() %&gt;% mutate(RF = data %&gt;% map(.,~as.data.frame(.) %&gt;% mutate(RF = predict(m_rf, .)) %&gt;% dplyr::select(RF))) 3.4 Model evaluation Obtain metrics Model performance will be evaluated using the following metrics: Relative Root Mean Square Error (RRMSE%), Percentage Lack of Precision (PLP%), Percentage Lack of Accuracy (PLA%), and Mean Absolute Error (MAE, same units that variable of response). Metrics equations are below: \\[ RRMSE = \\frac{\\sqrt{\\frac{1}{n} \\sum \\left(Pred_i - Obs_i \\right)^2}}{\\bar{Obs}} \\times 100\\% \\] \\(PLP = \\frac{2 S_{Obs} S_{Pred} (1-r)}{\\frac{1}{n} \\sum{(Pred_i - Obs_i)^2} }* 100\\) \\(PLA = \\frac{(\\bar{Obs}-\\bar{Pred})^2 + (S_{Obs} - S_{Pred})^2}{\\frac{1}{n} \\sum{(Pred_i - Obs_i)^2} } *100\\) \\(MAE = \\frac{1}{n}\\sum|Obs_i - Pred_i|\\) Lower values of RRMSE and MAE indicate better model performance. Similarly, for PLA and PLP, lower values reflect better model accuracy and precision. For instance, a PLP value of 90% and a PLA value of 10% suggest that the model predicts with higher accuracy than precision. For more details, refer to Correndo et al., 2021 and Correndo et al., 2022. labs &lt;- rf_pred %&gt;% unnest(c(RF,data )) %&gt;% dplyr::select(Yield, RF) %&gt;% pivot_longer(RF,names_to = &quot;Model&quot;, values_to = &quot;Pred&quot;) %&gt;% drop_na() %&gt;% ungroup() %&gt;% group_by(Model) %&gt;% summarise(RRMSE = round(metrica::RRMSE(obs = Yield, pred =Pred)[[1]]*100,0), PLP = round(metrica::PLP(obs = Yield, pred =Pred)[[1]],0), PLA = round(metrica::PLA(obs = Yield, pred =Pred)[[1]],0), MAE = round(mean(abs(Yield - Pred)),0) ) %&gt;% pivot_longer(-Model, names_to = &quot;Metric&quot;, values_to = &quot;Val&quot;) %&gt;% mutate(Label = paste(Metric, &quot;=&quot;, Val)) ## Adding missing grouping variables: `ID`, ## `year`, `Farm` # Prepare label positions num_metrics &lt;- n_distinct(labs$Metric) y_positions &lt;- seq(20000, by = -1000, length.out = num_metrics) labs &lt;- labs %&gt;% mutate(y_position = seq(20000, by = -1000, length.out = num_metrics)) Plot Observed vs predicted Plot the observed yield monitor data against the predicted yield data to evaluate the model’s performance. Additionally, create maps for each year using both predicted and observed data to assess whether the model accurately captures the spatial distribution within the field. Obs_pred_YP &lt;- test_df %&gt;% dplyr::select(Farm,Crop, Year, ID, X,Y, Yield, Peak_GCVI) %&gt;% left_join(rf_pred %&gt;% unnest(c(data,RF)) %&gt;% dplyr::select(RF, Year), by = c(&quot;ID&quot;, &quot;Year&quot;, &quot;Farm&quot;) ) %&gt;% ggplot()+ geom_point(aes(x = RF, y = Yield, fill = Farm), shape = 21, alpha =.5, size = 3)+ geom_abline(intercept = 0, slope = 1, linetype = &quot;dotted&quot;, size = 1)+ scale_x_continuous(breaks = seq(0, 20000, 5000), limits = c(0,20000))+ scale_y_continuous(breaks = seq(0, 20000, 5000), limits = c(0,20000))+ geom_text(data =labs, aes(x = 0, y = y_position, label = Label), hjust = 0, size =3) + labs(y = expression(Observed~yield~(kg~ha^-1)), x = expression(Predicted~yield~(kg~ha^-1)))+ scale_fill_manual(values = c(&quot;#415a77&quot;, &quot;#52796f&quot;,&quot;#936639&quot;,&quot;#adb5bd&quot;), aesthetics = &quot;fill&quot;)+ theme_bw()+ theme(strip.text = element_text(size = 11,family = &quot;sans&quot;), strip.background = element_blank(), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), panel.grid.minor = element_blank(), axis.text = element_text(size = 10), axis.title = element_text(size = 11), axis.ticks.length=unit(-0.1, &quot;cm&quot;)) Obs_pred_YP ggsave(&quot;3_Output/4_Yield_pred/Obs_pred_YP.png&quot;, height = 4, width = 5.5) yearYields &lt;- test_df %&gt;% dplyr::select(Farm,Crop, Year, ID, X,Y, Yield, Peak_GCVI) %&gt;% left_join(rf_pred %&gt;% unnest(c(data,RF)) %&gt;% dplyr::select(RF, Year), by = c(&quot;ID&quot;, &quot;Year&quot;, &quot;Farm&quot;) ) %&gt;% dplyr::filter(Farm == &quot;IL5&quot;) %&gt;% pivot_longer(c(Yield, RF), names_to = &quot;var&quot;,values_to = &quot;val&quot; ) %&gt;% ggplot() + geom_sf(aes(color = val), size = 1)+ scale_color_gradientn(colors = c(&quot;#3b0001&quot;,&quot;#be0003&quot;,&quot;#ff4903&quot;,&quot;#ffdc00&quot;, &quot;#559d03&quot;,&quot;#075e07&quot;,&#39;#161f0c&#39;)) + facet_grid(Year~var)+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ theme(axis.text = element_blank(), axis.ticks = element_blank(), strip.background = element_blank(),strip.text = element_text(size = 10), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;bottom&quot;, legend.text = element_text(size = 9), legend.key.height= unit(.2, &#39;cm&#39;), legend.key.width= unit(.9, &#39;cm&#39;)) yearYields ggsave(&quot;3_Output/4_Yield_pred/yearYields.png&quot;, height = 6, width = 4.5) 3.5 Save prediction A shapefile was created containing both the observed yield monitor data and the predicted yield data using from Sentinel-2. Field IL5 was selected for this purpose because it was not used in training the models and includes four years of yield monitor data, starting from 2017, when Sentinel-2 data became available. YM_df &lt;- test_df %&gt;% dplyr::select(Farm,Crop, Year, ID, X,Y, Yield, Peak_GCVI) %&gt;% left_join(rf_pred %&gt;% unnest(c(data,RF)) %&gt;% dplyr::select(RF, Year), by = c(&quot;ID&quot;, &quot;Year&quot;, &quot;Farm&quot;) ) %&gt;% dplyr::filter(Farm == &quot;IL5&quot;) %&gt;% rename(Ypred = RF, Yobs = Yield, crp = Crop) %&gt;% dplyr::select(-c(year,Farm)) sf::write_sf(YM_df, paste0(&quot;1_Data/5_YieldPred/YM_df&quot;, FIELD_NAME, &quot;_Ypred.shp&quot;),append = F) 3.6 Reference Bivand R, Pebesma E, Gomez-Rubio V (2013). Applied spatial data analysis with R, Second edition. Springer, NY. https://asdar-book.org/. Breiman, Leo. “Random forests.” Machine learning 45 (2001): 5-32. Correndo, A. A., Hefley, T. J., Holzworth, D. P., &amp; Ciampitti, I. A. (2021). Revisiting linear regression to test agreement in continuous predicted-observed datasets. Agricultural Systems, 192, 103194. Correndo, A. A., Rosso, L. H. M., Hernandez, C. H., Bastos, L. M., Nieto, L., Holzworth, D., &amp; Ciampitti, I. A. (2022). metrica: an R package to evaluate prediction performance of regression and classification point-forecast models. Journal of Open Source Software, 7(79), 4655. Liaw, A., Wiener, M. (2002). Classification and Regression by randomForest. R News 2(3), 18–22. Pebesma E (2018). “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal, 10(1), 439–446. doi:10.32614/RJ-2018-009, https://doi.org/10.32614/RJ-2018-009. Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686. "],["spatio-temporal-variation-models.html", "4 Spatio-temporal variation models 4.1 Import Libraries 4.2 Upload data 4.3 GAMs 4.4 CART 4.5 Reference", " 4 Spatio-temporal variation models To assess spatio-temporal yield variation in response to precipitation within a field using both observed and predicted yield data, two methodologies will be employed: Generalized Additive Models (GAMs): To obtain Spatially Varying Response Parameters (SVRP) across the field. Classification and Regression Trees (CART): To classify different types of yield responses to precipitation within the field, based on the previously obtained SVRP. 4.1 Import Libraries # Packages to be used library_names &lt;- c(&quot;sp&quot;, # (Bivand et al., 2012) &quot;sf&quot;, # (Pebesma, 2018) &quot;mgcv&quot;, # GAMs (Wood,2017) &quot;rpart&quot;, # Regression tree &quot;rpart.plot&quot;, # CART (Therneau et al., 2015) &quot;partykit&quot;, &quot;tidyverse&quot;) # (Wickham et al., 2019) # Iterate over each library name for (lib_name in library_names) { # Check if the library is already installed if (!require(lib_name, character.only = TRUE)) { # If the library is not installed, install it install.packages(lib_name, dependencies = TRUE) # Load the library library(lib_name, character.only = TRUE) } else { # If the library is already installed, load it library(lib_name, character.only = TRUE) } } # Palette color figures # grad_id &lt;- c(&quot;#99e2b4&quot;, &quot;#88d4ab&quot;, &quot;#78c6a3&quot;, &quot;#67b99a&quot;, &quot;#56ab91&quot;, &quot;#469d89&quot;, &quot;#358f80&quot;, &quot;#248277&quot;, &quot;#14746f&quot;, &quot;#036666&quot;, &quot;#025959&quot;, &quot;#014c4c&quot;, &quot;#013f3f&quot;, &quot;#013232&quot;, &quot;#012525&quot;) grad_bl &lt;- c(&quot;#c2e0f0&quot;, &quot;#b3d8ea&quot;, &quot;#a3cfe4&quot;, &quot;#89c2d9&quot;, &quot;#61a5c2&quot;, &quot;#468faf&quot;, &quot;#2c7da0&quot;, &quot;#2a6f97&quot;, &quot;#014f86&quot;, &quot;#01497c&quot;, &quot;#013a63&quot;, &quot;#012a4a&quot;, &quot;#011d36&quot;, &quot;#011529&quot;, &quot;#010e1d&quot;, &quot;#010912&quot;) grad_MY &lt;- c(&quot;#dad7cd&quot;, &quot;#a3b18a&quot;, &quot;#588157&quot;, &quot;#3a5a40&quot;, &quot;#344e41&quot;, &quot;#2c4238&quot;, &quot;#243630&quot;, &quot;#1c2a28&quot;) 4.2 Upload data ######### ADD FIELD NAME. Example: IL5 ############# FIELD_NAME &lt;- &quot;IL5&quot; ### Obtain each datasets ### YM_df &lt;- read_sf(paste0(&quot;1_Data/5_YieldPred/YM_df&quot;, FIELD_NAME, &quot;_Ypred.shp&quot;)) %&gt;% pivot_longer(c(Yobs, Ypred), names_to = &quot;Variable&quot;, values_to = &quot;Value&quot;) %&gt;% mutate(Value = round(Value, 0)) pp_periods &lt;- read.csv(paste0(&quot;1_Data/4_CP/CP_&quot;,FIELD_NAME,&quot;.csv&quot;)) %&gt;% mutate(Start_moment = str_replace(Start_moment, &quot;-&quot;, &quot;_&quot;)) %&gt;% pivot_wider(names_from = c(Start_moment, Period), values_from = CR) %&gt;% dplyr::filter(Year %in%c(unique(YM_df$Year))) %&gt;% dplyr::select(Year,May_1_90) %&gt;% rename(CP = May_1_90) df &lt;- YM_df %&gt;% left_join(pp_periods, by = c(&quot;Year&quot;)) %&gt;% group_by(Variable) %&gt;% nest() 4.3 GAMs GAMs, which are hierarchical models, are flexible analytical frameworks for capturing complex and non-linear interactions within a data (Wood, 2017). By using GAMs, we can obtain yield responses to precipitation at the pixel level within the field. In this framework, the first level of the model describes the crop yield (\\(Y_i\\)) for the \\(i^{th}\\) observation. The crop yield (\\(Y_i\\)) was assumed to follow a normal distribution with expected value \\(\\mu_i\\) and variance \\(\\sigma^2\\): \\(Y_i \\sim Normal(\\mu_i, \\sigma^2)\\) In the second level of the model, \\(\\mu_i\\) was defined as: \\(\\mu_i = \\beta_0 + f(Lon_i, Lat_i, CP_i)\\), where \\(\\beta_0\\) is the intercept term; and \\(f(Lon_i, Lat_i, CP_i)\\) is a tensor product smooth function of latitude (\\(Lat_i\\)), longitude (\\(Lon_i\\)), and cumulative precipitation (\\(CP_i\\)) with basis function thin plate spline for the spatial coordinates (Wood, 2003) and a cubic regression spline for cumulative precipitation variable. The complexity of the model is controlled by smoothing parameters, where k=(400,3) specifies the basis dimension limits, with 400 basis functions allocated for the interaction of spatial coordinates and 3 for cumulative precipitation. 4.3.1 Run models ## Observed yield monitor data model ## GAM_obs &lt;- bam(Value ~ te(X,Y, CP, bs= c(&quot;tp&quot;,&quot;cr&quot;), k =c(400, 2.6), d = c(2,1)), discrete = TRUE, nthreads = 16, data = df %&gt;% dplyr::filter(Variable == &quot;Yobs&quot;) %&gt;% unnest(data) ) #summary(GAM_obs) ## Observed yield monitor data model using sentinel-2 ## GAM_pred &lt;- bam(Value ~ te(X,Y, CP, bs= c(&quot;tp&quot;,&quot;cr&quot;), k =c(400, 2.6), d = c(2,1)), discrete = TRUE, nthreads = 16, data = df %&gt;% dplyr::filter(Variable == &quot;Ypred&quot;) %&gt;% unnest(data) ) #summary(GAM_pred) 4.3.2 Obtain predictions Use the original dataset to evaluate later observed versus predicted for observed yield monitor data and predicted monitor data using sentinel-2. pred &lt;- df %&gt;% mutate(pred = map2(data, Variable, ~{ if (.y == &quot;Yobs&quot;) { .x %&gt;% bind_cols(predict(GAM_obs, df %&gt;% dplyr::filter(Variable==&quot;Yobs&quot;) %&gt;% unnest(data), se.fit = TRUE, type = &quot;response&quot;) %&gt;% as.data.frame() %&gt;% rename(&quot;Yield_hat&quot; = 1)) %&gt;% dplyr::select(ID,X,Y, Year, Value, Yield_hat, CP) } else if (.y == &quot;Ypred&quot;) { .x %&gt;% bind_cols(predict(GAM_pred, df %&gt;% dplyr::filter(Variable==&quot;Ypred&quot;) %&gt;% unnest(data), se.fit = TRUE, type = &quot;response&quot;) %&gt;% as.data.frame() %&gt;% rename(&quot;Yield_hat&quot; = 1)) %&gt;% dplyr::select(ID,X,Y, Year, Value, Yield_hat, CP) } else { .x } })) A dataset with more intervals of of cumulative precipitation was created (mm). For that, the minimum and maximum value of CP was obtained, in order to obtain more interval between that range. # New dataframe in order to have more intervals # within the range of Cum precipitation new_df &lt;- df %&gt;% mutate(df = map2(data, Variable, ~{ if (.y == &quot;Yobs&quot;){ .x %&gt;% st_drop_geometry() %&gt;% group_by(X,Y) %&gt;% mutate(min = min(CP), max = max(CP) ) %&gt;% dplyr::select(X,Y, min, max) %&gt;% distinct() %&gt;% mutate(CP = list(seq(min, max, 2))) %&gt;% unnest(CP) %&gt;% ungroup() } else if (.y == &quot;Ypred&quot;) { .x %&gt;% st_drop_geometry() %&gt;% group_by(X,Y) %&gt;% mutate(min = min(CP), max = max(CP) ) %&gt;% dplyr::select(X,Y, min, max) %&gt;% distinct() %&gt;% mutate(CP = list(seq(min, max, 2))) %&gt;% unnest(CP) %&gt;% ungroup() } else { .x # Return the original data if the variable is not Obs or pred } })) %&gt;% dplyr::select(-data) ## Prediction ## pred_df &lt;- new_df %&gt;% mutate(pred = map2(df, Variable, ~{ if (.y == &quot;Yobs&quot;){ .x %&gt;% bind_cols(predict(GAM_obs, new_df %&gt;% dplyr::filter(Variable ==&quot;Yobs&quot;) %&gt;% unnest(df), se.fit = TRUE, type = &quot;response&quot;) %&gt;% as.data.frame() %&gt;% rename(&quot;Yield_hat&quot; = 1)) %&gt;% dplyr::select(X,Y, Yield_hat,CP) } else if (.y == &quot;Ypred&quot;) { .x %&gt;% bind_cols(predict(GAM_pred, new_df %&gt;% dplyr::filter(Variable ==&quot;Ypred&quot;) %&gt;% unnest(df), se.fit = TRUE, type = &quot;response&quot;) %&gt;% as.data.frame() %&gt;% rename(&quot;Yield_hat&quot; = 1)) %&gt;% dplyr::select(X,Y, Yield_hat,CP) } else { .x # Return the original data if the variable is not Obs or pred } })) 4.3.3 Model evaluation Metrics values ## Check summary ## #summary(GAM_obs) #summary(GAM_pred) #gam.check(GAM_obs) #gam.check(GAM_pred) Model performance will be evaluated using the following metrics: Relative Root Mean Square Error (RRMSE%), Percentage Lack of Precision (PLP%), Percentage Lack of Accuracy (PLA%), and Mean Absolute Error (MAE, same units that variable of response). Metrics equations are below: \\[ RRMSE = \\frac{\\sqrt{\\frac{1}{n} \\sum \\left(Pred_i - Obs_i \\right)^2}}{\\bar{Obs}} \\times 100\\% \\] \\(PLP = \\frac{2 S_{Obs} S_{Pred} (1-r)}{\\frac{1}{n} \\sum{(Pred_i - Obs_i)^2} }* 100\\) \\(PLA = \\frac{(\\bar{Obs}-\\bar{Pred})^2 + (S_{Obs} - S_{Pred})^2}{\\frac{1}{n} \\sum{(Pred_i - Obs_i)^2} } *100\\) \\(MAE = \\frac{1}{n}\\sum|Obs_i - Pred_i|\\) Lower values of RRMSE and MAE indicate better model performance. Similarly, for PLA and PLP, lower values reflect better model accuracy and precision. For instance, a PLP value of 90% and a PLA value of 10% suggest that the model predicts with higher accuracy than precision. For more details, refer to Correndo et al., 2021 and Correndo et al., 2022. Label &lt;- pred %&gt;% dplyr::select(-data) %&gt;% mutate(metrics = map2(pred, Variable, ~{ if (.y == &quot;Yobs&quot;){ .x %&gt;% st_drop_geometry() %&gt;% drop_na() %&gt;% mutate(RRMSE = round(metrica::RRMSE(obs=Value,pred=Yield_hat)[[1]]*100,0), PLP = round(metrica::PLP(obs=Value, pred=Yield_hat)[[1]],0), PLA = round(metrica::PLA(obs=Value, pred=Yield_hat)[[1]],0), MAE = round(mean(abs(Value - Yield_hat)),0)) %&gt;% dplyr::select(RRMSE, PLP, PLA, MAE) %&gt;% distinct() } else if (.y == &quot;Ypred&quot;) { .x %&gt;% st_drop_geometry() %&gt;% mutate(RRMSE = round(metrica::RRMSE(obs=Value,pred=Yield_hat)[[1]]*100,0), PLP = round(metrica::PLP(obs=Value, pred=Yield_hat)[[1]],0), PLA = round(metrica::PLA(obs=Value, pred=Yield_hat)[[1]],0), MAE = round(mean(abs(Value - Yield_hat)),0)) %&gt;% dplyr::select(RRMSE, PLP, PLA, MAE) %&gt;% distinct() } else { .x } })) %&gt;% dplyr::select(-pred) %&gt;% unnest(metrics) %&gt;% pivot_longer(-Variable, names_to = &quot;Metric&quot;, values_to = &quot;Value&quot;) %&gt;% mutate(Label = paste(Metric, &quot;=&quot;, Value)) # Prepare label positions num_metrics &lt;- n_distinct(Label$Metric) y_positions &lt;- seq(20000, by = -1000, length.out = num_metrics) Label &lt;- Label %&gt;%mutate(y_position = rep(y_positions, times = n_distinct(Variable))) Plot observed vs predicted Plot observed vs predicted for both observed yield monitor data (Yobs) and predicted yield monitor data (Ypred) using sentinel-2. The color of the points correspond to each pixel within the field. ObsPred &lt;- pred %&gt;% dplyr::select(-data) %&gt;% unnest(pred) %&gt;% group_by(X,Y) %&gt;% dplyr::filter(Variable != &quot;Pgcvi&quot;) %&gt;% mutate(ID = cur_group_id()) %&gt;% ungroup() %&gt;% ggplot()+ geom_point(aes(x = Yield_hat, y =Value, fill = ID), shape = 21, size = 2.5,color=&quot;black&quot;,alpha=.7, show.legend=F)+ scale_fill_gradientn(colors = grad_id)+ geom_abline(intercept = 0, slope = 1, linetype = &quot;dotted&quot;, size = 1)+ scale_x_continuous(breaks = seq(0, 20000, 5000), limits = c(0,20000))+ scale_y_continuous(breaks = seq(0, 20000, 5000), limits = c(0,20000))+ facet_wrap(~Variable)+ geom_text(data = Label, aes(x = 0, y = y_position, label = Label), hjust = 0, size =3) + labs(y = expression(Observed~yield~(kg~ha^-1)), x = expression(Predicted~yield~(kg~ha^-1)))+ theme_bw()+ theme(strip.text = element_text(size = 11,family = &quot;sans&quot;), strip.background = element_blank(), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), panel.grid.minor = element_blank(), axis.text = element_text(size = 10), axis.title = element_text(size = 11), axis.ticks.length=unit(-0.1, &quot;cm&quot;)) ObsPred ggsave(paste0(&quot;3_Output/5_GAM_Obs_Pred/ObsPred_&quot;,FIELD_NAME, &quot;.png&quot;), height = 3.5, width = 6) 4.3.4 Spatially Varying Parameters Obtain derivatives Spatially varying response parameters were derived from the GAM. Maximum yield at each coordinate was determined based on the first derivative of yield response to cumulative precipitation: it was obtained at the point where the derivative crosses zero, or at the point closest to zero if the maximum is not reached. For a flat yield response, the minimum extreme of cumulative precipitation was used. Additionally, the corresponding cumulative precipitation that maximizes yield was identified. pred_df &lt;- pred_df %&gt;% dplyr::select(-df) %&gt;% unnest(pred) %&gt;% ungroup() %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id()) %&gt;% ungroup() %&gt;% group_by(Variable, X,Y) %&gt;% mutate(CP = round(CP, 3))%&gt;% # Calculate derivative mutate(der1 = c(NA, diff(Yield_hat)/diff(CP))) write.csv(pred_df, paste0(&quot;1_Data/6_GAMs_pred/pred_&quot;,FIELD_NAME,&quot;.csv&quot;), row.names = F) max_CP &lt;- pred_df %&gt;% mutate(der1_sign_change = c(NA, diff(sign(der1))), count = any(der1_sign_change != 0), reach_max = case_when(count == TRUE ~ &quot;yes&quot;, TRUE ~ &quot;no&quot; )) %&gt;% dplyr::filter(der1 !=is.na(der1)) %&gt;% mutate(mean = mean(der1), sd = sd(der1), cv = abs((sd / mean) * 100), ## Variation of the 1st derivative ## cv_range = case_when( cv &lt;= 80 ~ &quot;No_var&quot;, cv &gt; 80 ~ &quot;Var&quot; )) %&gt;% group_by(Variable,X,Y) %&gt;% mutate(row_number = row_number()) %&gt;% # The first row where the derivative changes sign was found. mutate(first_sign_change_row = min(row_number[der1_sign_change != 0], na.rm = TRUE)) %&gt;% group_by(Variable,X,Y, reach_max, cv_range) %&gt;% nest() %&gt;% mutate( check_resp = map2(data, reach_max,~{ if (.y == &quot;yes&quot;) { .x %&gt;% dplyr::filter(row_number &lt; first_sign_change_row) %&gt;% mutate(check_resp = mean(der1, na.rm = TRUE)) %&gt;% dplyr::select(check_resp) %&gt;% as.data.frame() %&gt;% unique() } else { .x %&gt;% mutate(check_resp = 0) %&gt;% dplyr::select(check_resp) %&gt;% as.data.frame() %&gt;% unique() } })) %&gt;% unnest(check_resp) %&gt;% unnest(data) %&gt;% mutate(resp = case_when(check_resp &lt; 0 ~ &quot;negative_resp&quot;, TRUE ~ &quot;resp&quot;)) %&gt;% group_by(Variable,X,Y, reach_max, cv_range, resp) %&gt;% nest() %&gt;% # dplyr::filter(reach_max == &quot;no&quot; &amp; resp == &quot;resp&quot; ) mutate(max_CP = case_when( ## when reach maximum yield ## reach_max == &quot;yes&quot; &amp; resp == &quot;resp&quot; ~ data %&gt;% map(.,~as.data.frame(.) %&gt;% dplyr::filter(der1_sign_change != 0) %&gt;% dplyr::select(CP) %&gt;% rename(max_CP = CP)), ## when plateau but is negative (false maximum) ## reach_max == &quot;yes&quot; &amp; resp == &quot;negative_resp&quot; ~ data %&gt;% map(.,~as.data.frame(.) %&gt;% dplyr::filter(der1 != is.na(der1)) %&gt;% dplyr::filter(Yield_hat == max(Yield_hat)) %&gt;% dplyr::select(CP)%&gt;% rename(max_CP = CP)), ## Don&#39;t reach maximum but is not a flat resp., select the point more near to 0 ## reach_max == &quot;no&quot; &amp; cv_range == &quot;Var&quot; &amp; resp == &quot;resp&quot; ~ data %&gt;% map(.,~as.data.frame(.) %&gt;% dplyr::filter(der1 != is.na(der1)) %&gt;% dplyr::filter(abs(der1) == min(abs(der1))) %&gt;% dplyr::select(CP)%&gt;% rename(max_CP = CP)), ## Flat response: select the maximum yield ## reach_max == &quot;no&quot; &amp; cv_range == &quot;No_var&quot; &amp; resp == &quot;resp&quot; ~ data %&gt;% map(.,~as.data.frame(.) %&gt;% dplyr::filter(der1 != is.na(der1)) %&gt;% dplyr::filter(Yield_hat == max(Yield_hat)) %&gt;% dplyr::select(CP)%&gt;% rename(max_CP = CP)))) %&gt;% unnest(max_CP) %&gt;% unnest(data) %&gt;% dplyr::filter(CP == max_CP) %&gt;% ungroup() %&gt;% dplyr::select(-c(mean, sd, cv, count)) plot derivative to check Plot the derivative for both observed yield (Yobs) and predicted yield (Ypred) at specific coordinates within the field to determine if the crop yield response to precipitation is consistent at those coordinates using both yields variables. For example, a negative response using Yobs in the yield data might differ significantly when compared to the Ypred response at the same coordinate, indicating potential discrepancies between the Yobs and Ypred data. pred_df %&gt;% dplyr::filter(Variable == &quot;Yobs&quot;) %&gt;% ungroup() %&gt;% dplyr::filter(ID %in% c(10,100,500,1000,1500,2000)) %&gt;% pivot_longer(c(Yield_hat, der1), names_to = &quot;Var&quot;,values_to =&quot;Val&quot;) %&gt;% ggplot(aes(x = CP, y = Val, group = ID))+ geom_line(linewidth = .1)+ geom_vline(aes(xintercept = CP), linetype = &quot;dotted&quot;, data = max_CP %&gt;% dplyr::filter(Variable == &quot;Yobs&quot;) %&gt;% dplyr::filter(ID %in% c(10,100,500,1000,1500,2000))) + facet_grid(Var~ID, scales = &quot;free_y&quot;, labeller = labeller(Var = c(Yield_hat = &quot;Predicted yield&quot;, der1 = &quot;1st Derivative&quot;)))+ labs(x = &quot;Cumulative precipitation (mm)&quot;, y = &quot;&quot;)+ theme_bw()+ theme(strip.background = element_blank(), strip.text = element_text(size = 8), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), panel.grid.minor = element_blank(), axis.text = element_text(size = 7), axis.title = element_text(size = 8), axis.ticks.length=unit(-0.1, &quot;cm&quot;)) pred_df %&gt;% dplyr::filter(Variable == &quot;Ypred&quot;) %&gt;% ungroup() %&gt;% dplyr::filter(ID %in% c(10,100,500,1000,1500,2000)) %&gt;% pivot_longer(c(Yield_hat, der1), names_to = &quot;Var&quot;,values_to =&quot;Val&quot;) %&gt;% ggplot(aes(x = CP, y = Val, group = ID))+ geom_line(linewidth = .1)+ geom_vline(aes(xintercept = CP), linetype = &quot;dotted&quot;, data = max_CP %&gt;% dplyr::filter(Variable == &quot;Ypred&quot;) %&gt;% dplyr::filter(ID %in% c(10,100,500,1000,1500,2000))) + facet_grid(Var~ID, scales = &quot;free_y&quot;, labeller = labeller(Var = c(Yield_hat = &quot;Predicted yield&quot;, der1 = &quot;1st Derivative&quot;)))+ labs(x = &quot;Cumulative precipitation (mm)&quot;, y = &quot;&quot;)+ theme_bw()+ theme(strip.background = element_blank(), strip.text = element_text(size = 8), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), panel.grid.minor = element_blank(), axis.text = element_text(size = 7), axis.title = element_text(size = 8), axis.ticks.length=unit(-0.1, &quot;cm&quot;)) Obtain SVRP Growth rate was calculated from the start to the maximum yield, while decay rate was assessed from the maximum yield to the end. If the maximum yield is not reached, a rate of 0 is assigned, and it is noted in the dataset that the maximum yield response to cumulative rainfall was not achieved at that coordinate. ## Dataframe ## param_df &lt;- pred_df %&gt;% dplyr::filter(der1 != is.na(der1)) %&gt;% left_join(max_CP %&gt;% dplyr::select(Variable, ID, CP, reach_max) %&gt;% rename(max_CP = CP), by = c(&quot;ID&quot;, &quot;Variable&quot;)) %&gt;% group_by(Variable,ID) %&gt;% nest() %&gt;% mutate( ## Growth rate ## growth_rate = data %&gt;% map(., ~as.data.frame(.) %&gt;% dplyr::filter(CP &lt;= max_CP) %&gt;% mutate(growth_rate =case_when( max_CP == min(CP)~0, max_CP&gt;min(CP)~round((max(Yield_hat)-min(Yield_hat))/(max(CP)-min(CP)), 3)))%&gt;% dplyr::select(growth_rate) %&gt;% unique()), ## Decay rate ## decay_rate = data %&gt;% map(., ~as.data.frame(.) %&gt;% dplyr::filter(CP &gt;= max_CP) %&gt;% mutate(decay_rate =case_when( max_CP == max(CP)~0, TRUE~round((max(Yield_hat)-min(Yield_hat))/(max(CP)-min(CP)),3))) %&gt;% dplyr::select(decay_rate) %&gt;% unique())) %&gt;% unnest(c(data,growth_rate, decay_rate)) %&gt;% mutate(max_Yield = round(max(Yield_hat),1)) %&gt;% dplyr::select(Variable,ID,X,Y,max_Yield,max_CP, growth_rate, decay_rate, reach_max) %&gt;% unique() %&gt;% mutate(reach_max = as.factor(case_when(reach_max == &quot;yes&quot; ~1, TRUE ~0))) write.csv(param_df, paste0(&quot;1_Data/7_SVRP/param_&quot;,FIELD_NAME,&quot;.csv&quot;), row.names = FALSE) Plot the SVRP within the field Plot maps of each Spatially Varying Response Parameter to visualize the spatial distribution of these variables across the field. ## Path to the folder containing the SVRP files files &lt;- data.frame(path_CART = as.vector(list.files(&quot;1_Data/7_SVRP&quot;, recursive = T, full.names = T, pattern = &quot;.csv&quot;))) ## Plot and save map figures ## Vars &lt;- unique(YM_df$Variable) for(v in Vars) { map_maxY &lt;- YM_df %&gt;% dplyr::filter(Variable == v) %&gt;% dplyr::select(ID,X,Y, geometry, Variable) %&gt;% unique() %&gt;% st_as_sf() %&gt;% left_join(param_df %&gt;% dplyr::filter(Variable == v), by = c(&quot;ID&quot;, &quot;Variable&quot;) ) %&gt;% ggplot()+ geom_sf(aes(color = max_Yield), size = 0.7)+ scale_color_gradientn(colors = grad_MY,breaks = seq(2000, 24000, 2000))+ labs(color = expression(Maximum~yield~(kg~ha^-1)))+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ guides(color = guide_colorbar(title.position = &quot;top&quot;, title.hjust = 0.5)) + theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;bottom&quot;, legend.text = element_text(size = 9), legend.title = element_text(size = 10), legend.key.height = unit(.2, &#39;cm&#39;), legend.key.width = unit(.95, &#39;cm&#39;)) map_CP &lt;- YM_df %&gt;% dplyr::filter(Variable == v) %&gt;% dplyr::select(ID,X,Y, geometry, Variable) %&gt;% unique() %&gt;% st_as_sf() %&gt;% left_join(param_df %&gt;% dplyr::filter(Variable == v), by = c(&quot;ID&quot;, &quot;Variable&quot;) ) %&gt;% ggplot()+ geom_sf(aes(color = max_CP), size = 0.7)+ scale_color_gradientn(colors = grad_bl)+ labs(color = expression(CP~maximize~yield~(mm)))+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ guides(color = guide_colorbar(title.position = &quot;top&quot;, title.hjust = 0.5)) + theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;bottom&quot;, legend.text = element_text(size = 9), legend.title = element_text(size = 10), legend.key.height = unit(.2, &#39;cm&#39;), legend.key.width = unit(.95, &#39;cm&#39;)) map_GR &lt;- YM_df %&gt;% dplyr::filter(Variable == v) %&gt;% dplyr::select(ID,X,Y, geometry, Variable) %&gt;% unique() %&gt;% st_as_sf() %&gt;% left_join(param_df %&gt;% dplyr::filter(Variable == v), by = c(&quot;ID&quot;, &quot;Variable&quot;) ) %&gt;% ggplot()+ geom_sf(aes(color = growth_rate), size = 0.7)+ scale_color_viridis_c(option = &quot;A&quot;, direction = -1)+ labs(color = expression(Growth~rate~(kg~ha^{-1}~mm^{-1})))+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ guides(color = guide_colorbar(title.position = &quot;top&quot;, title.hjust = 0.5)) + theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;bottom&quot;, legend.text = element_text(size = 9), legend.title = element_text(size = 10), legend.key.height = unit(.2, &#39;cm&#39;), legend.key.width = unit(.95, &#39;cm&#39;)) map_DR &lt;- YM_df %&gt;% dplyr::filter(Variable == v) %&gt;% dplyr::select(ID,X,Y, geometry, Variable) %&gt;% unique() %&gt;% st_as_sf() %&gt;% left_join(param_df %&gt;% dplyr::filter(Variable == v), by = c(&quot;ID&quot;, &quot;Variable&quot;) ) %&gt;% ggplot()+ geom_sf(aes(color = decay_rate), size = 0.7)+ scale_color_viridis_c(option = &quot;A&quot;, direction = -1)+ labs(color = expression(Decay~rate~(kg~ha^{-1}~mm^{-1})))+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ guides(color = guide_colorbar(title.position = &quot;top&quot;, title.hjust = 0.5)) + theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;bottom&quot;, legend.text = element_text(size = 9), legend.title = element_text(size = 10), legend.key.height = unit(.2, &#39;cm&#39;), legend.key.width = unit(.95, &#39;cm&#39;)) map_SVP &lt;- cowplot::plot_grid(map_maxY,map_CP, map_GR, map_DR, nrow=1, rel_widths = c(1,1,1,1)) ggsave(paste0(&quot;3_Output/6_SVRP/mapSVP_&quot;,FIELD_NAME,&quot;_&quot;,v, &quot;.png&quot;), height = 2, width = 8.3) } map_SVP 4.4 CART To classify responses to cumulative precipitation within the field, Classification and Regression Tree (CART) methodology was used, which divides observations into increasingly homogeneous groups (Breiman et al., 2017). The response variable for this classification was the cumulative precipitation that maximizes yield. Explanatory variables included Maximum Yield, Growth Rate, Decay Rate, and a binary indicator of whether maximum yield was reached, derived from the GAM model. ########################################################################### #################### FUNCTION CART to automatize CART #################### ########################################################################### rt_fn &lt;- function(Farm_name, var_name, data){ # Filter data for the specific crop # Run Regression tree rt &lt;- rpart::rpart(max_CP ~ growth_rate + decay_rate + reach_max + max_Yield, method = &quot;anova&quot;, control = rpart.control(cp = 0.05,maxdepth = 2), data = data) #Save CART plot png(paste0(&quot;3_Output/7_CART/1_CART_plot/&quot;,Farm_name, &quot;_&quot;,var_name, &quot;.png&quot;)) rpart.plot(rt) dev.off() # Get terminal node (leaf) assignments and create group names data &lt;- data %&gt;% ungroup() %&gt;% mutate(node = predict(rt, type = &quot;vector&quot;),# Add node predictions group = factor(node)) %&gt;%# Convert node numbers to factor for labeling mutate(group = as.integer(group)) %&gt;% # Ensure group is integer for sorting if needed arrange(group) %&gt;%# arrange by group for consistent labeling mutate(group = paste0(&quot;G&quot;, dense_rank(group)))# Create unique group names # Example of further usage, such as joining and summarizing regT_df &lt;- pred_df %&gt;% dplyr::filter(Variable == var_name) %&gt;% ungroup() %&gt;% dplyr::select(ID, CP, Yield_hat) %&gt;% left_join(data, by = &quot;ID&quot;) %&gt;% group_by(group, CP) %&gt;% mutate(mean_Y = mean(Yield_hat), Q975 = quantile(Yield_hat, 0.95), Q025 = quantile(Yield_hat, 0.05)) %&gt;% ungroup() %&gt;% group_by(group) %&gt;% mutate(q975CP = quantile(max_CP, 0.95), q025CP = quantile(max_CP, 0.05)) write.csv(regT_df, paste0(&quot;1_Data/8_CART/CART_&quot;,Farm_name,&quot;_&quot;,var_name,&quot;.csv&quot;), row.names = FALSE) return(regT_df) } 4.4.1 Run CART # Obtain Files f_cart &lt;- data.frame(path_SVP = as.vector(list.files(&quot;1_Data/7_SVRP&quot;, recursive = T, full.names = T, pattern = &quot;.csv&quot;))) %&gt;% mutate(path_pred = as.vector(list.files(&quot;1_Data/6_GAMs_pred&quot;, pattern = &quot;.csv&quot;, recursive = T,full.names = T))) %&gt;% mutate(Farm= str_remove(path_SVP, &quot;1_Data/7_SVRP/param_&quot;), Farm = str_remove(Farm, &quot;.csv&quot;), .before = 1) %&gt;% ## Filter the farm/field that we are testing in the moment dplyr::filter(Farm == FIELD_NAME) Run this code that contains a function (rt_fn) previously created. rt_fn function: i) runs the CART model (rpart function) for each crop in each field; ii) Saves the CART tree figure; iii) create a dataframe splitting the data depending on the group. for (file in 1:nrow(f_cart)){ ## Upload files Farm &lt;- f_cart[file,1] param_df &lt;- read.csv(f_cart[file,2]) pred_df &lt;- read.csv(f_cart[file,3]) ## Run CART, write figures &amp; files in folder param_df %&gt;% ungroup() %&gt;% group_by(Variable) %&gt;% nest() %&gt;% mutate(cart = map2(.x = Variable, .y = data, # function created previously .f = ~rt_fn(Farm_name = Farm, var_name = .x, data = .y))) } 4.4.2 Obtain Figures files &lt;- data.frame(path_CART = as.vector(list.files(&quot;1_Data/8_CART&quot;, recursive = T, full.names = T, pattern = &quot;.csv&quot;))) %&gt;% mutate(Farm= str_remove(path_CART, &quot;1_Data/8_CART/CART_&quot;), Farm = str_remove(Farm, &quot;.csv&quot;),.before = 1) %&gt;% separate(Farm, into = c(&quot;Farm&quot;, &quot;Variable&quot;),sep = &quot;_(?=[^_]+$)&quot;) %&gt;% ## Filter the farm/field that we are testing in the moment dplyr::filter(Farm == FIELD_NAME) Create a figure that includes a map showing the distribution of groups within the field, the yield response to precipitation within each group across the field, and the range of each Spatially Varying Response Parameter within each group. ## Obtain figures and save ## for (file in 1:nrow(files)){ ## Upload files Farm &lt;- files[file,1] var_name &lt;- files[file,2] regT_df &lt;- read.csv(files[file,3]) ## Plot groups spatial distribution in the field map_gr &lt;- YM_df %&gt;% dplyr::filter(Variable == var_name) %&gt;% dplyr::select(X,Y) %&gt;% unique() %&gt;% group_by(X,Y) %&gt;% mutate(ID = cur_group_id()) %&gt;% ungroup() %&gt;% left_join(regT_df %&gt;% dplyr::select(group, ID) %&gt;% unique(), by = c(&quot;ID&quot;)) %&gt;% ggplot()+ geom_sf(aes(color = group), size =3)+ scale_color_manual(values =c(&quot;#61a5c2&quot;, &quot;#01497c&quot;,&quot;#011d36&quot;, &quot;#010912&quot;), aesthetics = c(&quot;color&quot;, &quot;fill&quot;))+ labs(color = &quot;Groups&quot;)+ scale_y_continuous(expand = c(.15,.15))+ scale_x_continuous(expand = c(.15,.15))+ guides(color = guide_legend(override.aes = list(size = 3), title.position = &quot;top&quot;, title.hjust = 0.5))+ theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill = &quot;#7f7f7f&quot;, color = &quot;#949494&quot;), panel.grid = element_line(color = &quot;#949494&quot;), legend.position = &quot;bottom&quot;, legend.text = element_text(size = 12), legend.title = element_text(size = 11), legend.key.height= unit(.2, &#39;cm&#39;), legend.key.width= unit(.4, &#39;cm&#39;)) ggsave(paste0(&quot;3_Output/7_CART/2_Field_classif/mapGr_&quot;,Farm,&quot;_&quot;,var_name,&quot;.png&quot;)) ## Plot type of response group_responses &lt;- regT_df %&gt;% ggplot()+ geom_rect(data = regT_df %&gt;% group_by(group) %&gt;% dplyr::select(group, ID,q975CP, q025CP, Yield_hat) %&gt;% dplyr::filter(row_number() == 1) %&gt;% unique(), aes(xmin = q025CP, xmax = q975CP),ymin = -Inf, ymax=Inf, fill = &quot;#274060&quot;,alpha=.2,show.legend = F)+ geom_ribbon(aes(x = CP, ymin = Q025, ymax = Q975,fill =group), alpha =0.9, show.legend = F)+ geom_line(aes(x = CP,y = mean_Y), color = &quot;Black&quot;, linewidth = 1,show.legend = F)+ geom_line(aes(x = CP,y = Q975), color=&quot;Black&quot;, linewidth=1,show.legend =F,linetype=&quot;dashed&quot;)+ geom_line(aes(x = CP,y = Q025), color=&quot;Black&quot;, linewidth=1,show.legend =F,linetype=&quot;dashed&quot;)+ facet_wrap(~group, nrow = 1)+ scale_color_manual(values = c(&quot;#61a5c2&quot;, &quot;#01497c&quot;,&quot;#011d36&quot;, &quot;#010912&quot;), aesthetics = c(&quot;color&quot;, &quot;fill&quot;))+ #scale_y_continuous(breaks = seq(0, 350, 40))+ expand_limits(y=0)+ #scale_x_continuous(breaks = seq(0, 550, 25))+ labs(x = &quot;Cumulative precipitation (mm)&quot;, y = expression(Predicted~yield~(kg~ha^{-1})))+ theme_bw()+ theme(strip.background = element_blank(), strip.text = element_text(size = 11), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), axis.text = element_text(size = 10), axis.title = element_text(size = 11), axis.ticks.length=unit(-0.1, &quot;cm&quot;)) ggsave(paste0(&quot;3_Output/7_CART/2_Field_classif/grResp_&quot;,Farm,&quot;_&quot;,var_name,&quot;.png&quot;), height = 3,width = 8) ## Plot parameters param_gr &lt;- regT_df %&gt;% dplyr::select(ID,max_CP, growth_rate,decay_rate, max_Yield,group) %&gt;% distinct() %&gt;% rename(&quot;CP maximize yield&quot; = max_CP, &quot;Maximum Yield&quot; = max_Yield, &quot;Growth rate&quot; = growth_rate, &quot;Decay rate&quot; = decay_rate) %&gt;% pivot_longer(c(`Maximum Yield`,`CP maximize yield`,`Growth rate`,`Decay rate`), names_to = &quot;Var&quot;, values_to = &quot;Val&quot;) %&gt;% mutate(Var = as.factor(Var), Var = fct_relevel(Var,&quot;Maximum Yield&quot;, &quot;CP maximize yield&quot;, &quot;Growth rate&quot;,&quot;Decay rate&quot;)) %&gt;% ungroup() %&gt;% group_by(Var, group) %&gt;% summarise(meanCl = mean(Val), q975Cl = quantile(Val, .975), q025Cl = quantile(Val, .025)) %&gt;% ungroup(group) %&gt;% mutate(mean = mean(meanCl), difMean = meanCl - mean) %&gt;% ggplot(aes(y = as.factor(group), x = meanCl)) + geom_point(size = 2)+ geom_errorbar(aes(xmin = q975Cl, xmax = q025Cl), width = 0)+ facet_wrap(~Var, scales = &quot;free_x&quot;, ncol = 4)+ labs(y = &quot;Group&quot;)+ theme_bw()+ theme(strip.background = element_blank(), strip.text = element_text(size = 10), panel.background = element_rect(fill = &quot;#eeeeee&quot;), panel.grid = element_line(color = &quot;#f8f9fa&quot;), axis.text = element_text(size = 9), axis.title = element_text(size = 10), axis.ticks.length=unit(-0.1, &quot;cm&quot;), axis.title.x = element_blank()) ggsave(paste0(&quot;3_Output/7_CART/2_Field_classif/paramGr_&quot;,Farm,&quot;_&quot;,var_name,&quot;.png&quot;), height = 2.8,width = 8) } ## Saving 7 x 5 in image ## `summarise()` has grouped output by &#39;Var&#39;. You can override using the `.groups` argument. ## Saving 7 x 5 in image ## `summarise()` has grouped output by &#39;Var&#39;. You can override using the `.groups` argument. map_gr group_responses param_gr 4.5 Reference Bivand R, Pebesma E, Gomez-Rubio V (2013). Applied spatial data analysis with R, Second edition. Springer, NY. https://asdar-book.org/. Pebesma E (2018). “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal, 10(1), 439–446. doi:10.32614/RJ-2018-009, https://doi.org/10.32614/RJ-2018-009. Correndo, A. A., Hefley, T. J., Holzworth, D. P., &amp; Ciampitti, I. A. (2021). Revisiting linear regression to test agreement in continuous predicted-observed datasets. Agricultural Systems, 192, 103194. Correndo, A. A., Rosso, L. H. M., Hernandez, C. H., Bastos, L. M., Nieto, L., Holzworth, D., &amp; Ciampitti, I. A. (2022). metrica: an R package to evaluate prediction performance of regression and classification point-forecast models. Journal of Open Source Software, 7(79), 4655. Therneau T, Atkinson B (2022). rpart: Recursive Partitioning and Regression Trees. R package version 4.1.19, https://CRAN.R-project.org/package=rpart. Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686. Wood, S.N., 2003. Thin Plate Regression Splines. Journal of the Royal Statistical Society Series B: Statistical Methodology 65, 95–114. https://doi.org/10.1111/1467-9868.00374 Wood, S.N., 2017. Generalized Additive Models: An Introduction with R, 2nd ed. Chapman and Hall/CRC. https://doi.org/10.1201/9781315370279 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
